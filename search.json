[
  {
    "objectID": "legionella_parser.html",
    "href": "legionella_parser.html",
    "title": "Directive for creating a script for your notebook",
    "section": "",
    "text": "Include all the libraries which should be used in this module. You can also import modules from other notebooks; here, we have imported the functions in the core notebook.\n\n# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\nos.chdir(core.PROJECT_DIR)",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "legionella_parser.html#testing",
    "href": "legionella_parser.html#testing",
    "title": "Directive for creating a script for your notebook",
    "section": "TESTING",
    "text": "TESTING\n\nf = LegionellaResults.from_results_tsv(\"./test_output/test_batch_output.tsv\")\nassert(len(f) == 2)\nassert(f.results_dict[\"sample_1\"][\"ST\"] == 23)\n\n\nf = LegionellaResults.from_tool_paths_dict(file_paths=  {\"sample_1\": {\"sbt_results\": \"test_input/Legionella/test.sbt.tsv\", \"lag1_blast_results\": \"test_input/Legionella/lag-1_blast.tsv\"},\n                                                            \"sample_2\": {\"sbt_results\": \"test_input/Legionella/test2.sbt.tsv\", \"lag1_blast_results\": \"test_input/Legionella/lag-1_blast_2.tsv\"}})\n\n\n\nf = LegionellaResults.from_tool_paths(legionella_sbt_results_tsv=\"test_input/Legionella/test.sbt.tsv\",\n                                      lag1_blast_tsv=\"test_input/Legionella/lag-1_blast.tsv\")\n\n\n\nf = LegionellaResults.from_tool_paths_tsv(tool_paths_tsv=\"test_input/Legionella/batch_parser_file_paths.tsv\")\n\nassert(len(f) == 4)\nassert(len(f.results_df) == 4)\nassert(len(f.results_df.columns) == 10)\n\nBlast output file test_input/Legionella/lag-1_blast_2.tsv empty. Assuming 0 blast hits.\n{'ST': 23, 'flaA': 2, 'pilE': 3, 'asd': 9, 'mip': 10, 'mompS': 2, 'proA': 1, 'neuA': 6, 'notes': 'Exact ST match, Heterozygous mompS alleles, High confidence mompS allele call', 'lag-1': '1'}\nBlast output file test_input/Legionella/lag-1_blast_2.tsv empty. Assuming 0 blast hits.\n{'ST': 182, 'flaA': 3, 'pilE': 4, 'asd': 1, 'mip': 3, 'mompS': 35, 'proA': 9, 'neuA': 11, 'notes': 'Exact ST match, Heterozygous mompS alleles, High confidence mompS allele call', 'lag-1': '0'}\nBlast output file test_input/empty_file.txt empty. Assuming 0 blast hits.\n{'ST': 182, 'flaA': 3, 'pilE': 4, 'asd': 1, 'mip': 3, 'mompS': 35, 'proA': 9, 'neuA': 11, 'notes': 'Exact ST match, Heterozygous mompS alleles, High confidence mompS allele call', 'lag-1': '0'}\nBlast output file test_input/Legionella/lag-1_blast_2.tsv empty. Assuming 0 blast hits.\n{'lag-1': '0'}\n\n\nLegionella SBT output empty at test_input/empty_file.txt\n\n\n\nsource\n\nlegionella_batch_parser\n\n legionella_batch_parser (file_path_tsv:pathlib.Path=None,\n                          output_file:pathlib.Path=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path_tsv\nPath\nNone\nPath to tsv containing file paths to the outputs from tools to be parsed. Must contain headers “sample_name”, “sbt_results”, and “lag1_blast_results”\n\n\noutput_file\nPath\nNone\nPath to output tsv\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nlegionella_parser\n\n legionella_parser (legionella_sbt_file:pathlib.Path=None,\n                    lag_1_blast_output:pathlib.Path=None,\n                    output_file:pathlib.Path=None, sample_name:str=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlegionella_sbt_file\nPath\nNone\nPath “*.sbt.tsv from legionella_sbt program”\n\n\nlag_1_blast_output\nPath\nNone\nPath to output from lag1_blast. Generated with blastn -query lag-1.fasta -subject assembly.fasta -outfmt “6 qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore”\n\n\noutput_file\nPath\nNone\nPath to output tsv\n\n\nsample_name\nstr\nNone\n\n\n\nReturns\nNone",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "template.html",
    "href": "template.html",
    "title": "Directive for creating a script for your notebook",
    "section": "",
    "text": "Libraries\nInclude all the libraries which should be used in this module. You can also import modules from other notebooks; here, we have imported the functions in the core notebook.\n\n# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\nos.chdir(core.PROJECT_DIR)\n\n\n\nFunctions\nAdd your code here below. If your notebook will be used as a console-script, you need to add a “cli”-function, at the end (see Coding in NBdev (Code execution and Input, output and options) on loop for more details)\n\n\nDirective for ensuring that the code in your notebook get executed as a script\nThe code-block here below is required to ensure that the code in the notebook is also transferred to the module (script), otherwise it will just be a notebook. See Coding in NBdev (Writing your own notebooks) on loop for more details.",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "ecoli_parser.html",
    "href": "ecoli_parser.html",
    "title": "Directive for creating a script for your notebook",
    "section": "",
    "text": "Include all the libraries which should be used in this Escherichia coli module, to create log the various operations to load input files, craete datastructures, maniplate and output desired results.\n\n# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\nos.chdir(core.PROJECT_DIR)",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "ecoli_parser.html#testing---empirical-dataset",
    "href": "ecoli_parser.html#testing---empirical-dataset",
    "title": "Directive for creating a script for your notebook",
    "section": "TESTING - empirical dataset",
    "text": "TESTING - empirical dataset\nPerform inline testing on two empirical datasets that verifies the functionality of the EcoliResults pipeline and datawrangling depending on the input",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "ecoli_parser.html#testing---syntehtic-data",
    "href": "ecoli_parser.html#testing---syntehtic-data",
    "title": "Directive for creating a script for your notebook",
    "section": "TESTING - syntehtic data",
    "text": "TESTING - syntehtic data\nDefines several scenarions of 12 samples representing syntehtic KMA .res content to perform several case specific results\n\nimport os\nfrom tempfile import TemporaryDirectory\nfrom pathlib import Path\n\ntest_cases = [\n    # sample_name, res_content, expected_oh, expected_stx, expected_eae, expected_ehxA\n    (\"sample1\", \"1__wzx__O103__X\\t100\\t100\\t60\\n2__wzy__O103__X\\t100\\t100\\t65\\n3__fliC__H2__X\\t100\\t100\\t70\", \"O103;H2\", \"-\", \"-\", \"-\"),\n    (\"sample2\", \"1__wzt__O8__X\\t100\\t100\\t60\\n2__wzm__O8__X\\t100\\t100\\t65\\n3__fliC__H10__X\\t100\\t100\\t70\\n4__stx2__stx2-a__X\\t100\\t100\\t90\\n5__eae__eae-5__X\\t100\\t100\\t80\", \"O8;H10\", \"stx2-a\", \"Positive\", \"-\"),\n    (\"sample3\", \"1__fliC__H7__X\\t100\\t100\\t70\", \"-;H7\", \"-\", \"-\", \"-\"),\n    (\"sample4\", \"bad_line\\n2__wzy__O111__X\\t100\\t100\\t70\\n3__fliC__H11__X\\t100\\t100\\t70\", \"-;H11\", \"-\", \"-\", \"-\"),\n    (\"sample5\", \"\", \"-;-\", \"-\", \"-\", \"-\"),\n    (\"sample6\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O157__X\\t100\\t100\\t65\\n3__wzt__O8__X\\t100\\t100\\t60\\n4__wzm__O8__X\\t100\\t100\\t65\\n5__fli__H2__X\\t100\\t100\\t70\", \"-;H2\", \"-\", \"-\", \"-\"),\n    (\"sample7\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O111__X\\t100\\t100\\t65\\n3__fliC__H9__X\\t100\\t100\\t70\", \"-;H9\", \"-\", \"-\", \"-\"),\n    (\"sample8\", \"1__fli__H1__X\\t100\\t100\\t70\\n2__fliC__H12__X\\t100\\t100\\t70\", \"-;H1\", \"-\", \"-\", \"-\"),\n    (\"sample9\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O157__X\\t100\\t100\\t65\\n3__wzt__O8__X\\t100\\t100\\t60\\n4__wzm__O8__X\\t100\\t100\\t65\\n5__fliC__H10__X\\t100\\t100\\t70\\n6__fli__H2__X\\t100\\t100\\t70\\n7__stx1__stx1-a__X\\t100\\t100\\t90\\n8__stx2__stx2-d__X\\t100\\t100\\t90\\n9__stx2__stx2-a__X\\t100\\t100\\t90\\n10__eae__eae-42-5__X\\t100\\t100\\t80\\n11__ehxA__ehxA-7__X\\t100\\t100\\t80\", \"-;H2\", \"stx1-a;stx2-a;stx2-d\", \"Positive\", \"Positive\"),\n    (\"sample10\", \"1__adk__adk__X\\t100\\t100\\t70\\n2__fliC__H4__X\\t100\\t100\\t70\", \"-;H4\", \"-\", \"-\", \"-\"),\n    (\"sample11\", \"1__eae__eae-1__X\\t100\\t94\\t70\\n2__fliC__H6__X\\t100\\t100\\t70\", \"-;H6\", \"-\", \"-\", \"-\"),\n    (\"sample12\", \"1__stx1__stx1a__X\\t100\\t100\\t80\\n2__stx2__stx2c__X\\t100\\t100\\t85\\n3__fli__H21__X\\t100\\t100\\t70\", \"-;H21\", \"stx1a;stx2c\", \"-\", \"-\"),\n]\n\nfor sample_name, res_content, expected_oh, expected_stx, expected_eae, expected_ehxA in test_cases:\n    with TemporaryDirectory() as tmpdir:\n        tmpdir = Path(tmpdir)\n        os.chdir(tmpdir)\n\n        res_dir = tmpdir / f\"examples/Results/{sample_name}/kma\"\n        res_dir.mkdir(parents=True)\n        res_file = res_dir / f\"{sample_name}.res\"\n        res_file.write_text(\"#Template\\tTemplate_Coverage\\tQuery_Identity\\tDepth\\n\" + res_content)\n\n        sheet = tmpdir / \"samplesheet.tsv\"\n        sheet.write_text(\n            \"sample_name\\tIllumina_read_files\\tNanopore_read_file\\tassembly_file\\torganism\\tvariant\\tnotes\\n\"\n            f\"{sample_name}\\tread1.fastq,read2.fastq\\t-\\t-\\tEcoli\\t-\\t-\\n\"\n        )\n\n        results = EcoliResults.from_samplesheet(sheet)\n        df = results.results_df\n        row = df.iloc[0]\n        \n        # general output and functionality test\n        assert row[\"sample_name\"] == sample_name\n        \n        if row[\"OH\"] != expected_oh:\n            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected OH: {expected_oh}\\nActual OH: {row['OH']}\")\n        assert row[\"OH\"] == expected_oh\n        \n        if row[\"stx\"] != expected_stx:\n            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected stx: {expected_stx}\\nActual stx: {row['stx']}\")\n        assert row[\"stx\"] == expected_stx\n\n        if row[\"eae\"] != expected_eae:\n            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected eae: {expected_eae}\\nActual eae: {row['eae']}\")\n        assert row[\"eae\"] == expected_eae\n\n        if row[\"ehxA\"] != expected_ehxA:\n            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected ehxA: {expected_ehxA}\\nActual ehxA: {row['ehxA']}\")\n        assert row[\"ehxA\"] == expected_ehxA\n\n        # sample specific information tests\n        \n        # without confliciting O and H typing, the OH column should be filled and the remaining four genes empty\n        if sample_name == \"sample1\": \n            assert row[\"wzx\"] == \"-\"\n            assert row[\"wzy\"] == \"-\"\n            assert row[\"wzt\"] == \"-\"\n            assert row[\"wzm\"] == \"-\"\n        # with conflicts the OH should remain empty and the four 'conflicting' gene information remain filled\n        elif sample_name == \"sample6\":\n            assert row[\"wzx\"] == \"O157\"\n            assert row[\"wzy\"] == \"O157\"\n            assert row[\"wzt\"] == \"O8\"\n            assert row[\"wzm\"] == \"O8\"\n        elif sample_name == \"sample10\":\n            assert row[\"Other\"] == \"adk\"\n\nprint(\"All 12 syntehtic E. coli sample inline tests passed.\")\n\nLogging started for examples/Log/sample1_kma_fbi.log\nProcessing .res file: examples/Results/sample1/kma/sample1.res\nSuccessfully processed sample: sample1\nLogging started for examples/Log/sample2_kma_fbi.log\nProcessing .res file: examples/Results/sample2/kma/sample2.res\nSuccessfully processed sample: sample2\nLogging started for examples/Log/sample3_kma_fbi.log\nProcessing .res file: examples/Results/sample3/kma/sample3.res\nSuccessfully processed sample: sample3\nLogging started for examples/Log/sample4_kma_fbi.log\nProcessing .res file: examples/Results/sample4/kma/sample4.res\nSuccessfully processed sample: sample4\nLogging started for examples/Log/sample5_kma_fbi.log\nProcessing .res file: examples/Results/sample5/kma/sample5.res\nSuccessfully processed sample: sample5\nLogging started for examples/Log/sample6_kma_fbi.log\nProcessing .res file: examples/Results/sample6/kma/sample6.res\nSuccessfully processed sample: sample6\nLogging started for examples/Log/sample7_kma_fbi.log\nProcessing .res file: examples/Results/sample7/kma/sample7.res\nSuccessfully processed sample: sample7\nLogging started for examples/Log/sample8_kma_fbi.log\nProcessing .res file: examples/Results/sample8/kma/sample8.res\nSuccessfully processed sample: sample8\nLogging started for examples/Log/sample9_kma_fbi.log\nProcessing .res file: examples/Results/sample9/kma/sample9.res\nSuccessfully processed sample: sample9\nLogging started for examples/Log/sample10_kma_fbi.log\nProcessing .res file: examples/Results/sample10/kma/sample10.res\nSuccessfully processed sample: sample10\nLogging started for examples/Log/sample11_kma_fbi.log\nProcessing .res file: examples/Results/sample11/kma/sample11.res\nSuccessfully processed sample: sample11\nLogging started for examples/Log/sample12_kma_fbi.log\nProcessing .res file: examples/Results/sample12/kma/sample12.res\nSuccessfully processed sample: sample12\nAll 12 syntehtic E. coli sample inline tests passed.",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "hello_world.html",
    "href": "hello_world.html",
    "title": "Additional Learning Resources",
    "section": "",
    "text": "Now that you’ve finished the getting started in ./GETTING_STARTED_WITH_TEMPLATE.md, you’ll notice the directory has many new files and folders. In this example $YOUR_REPO_NAME is template_nbdev_example so be sure to adjust accordingly.\nThere’s now\n./_docs\n.quarto\n./template_nbdev_example # This is the code autogenerated from the notebooks, you should only adjust this through your notebooks\n./template_nbdev_example/__pycache__\n./template_nbdev_example/__init__.py\n./template_nbdev_example/_modidx.py\n./template_nbdev_example/core.py\n./template_nbdev_example/hello_world.py\n./template_nbdev_example.egg-info # This is metadata about the package for pip\n_quarto.yml\nindex.ipynb # This is a notebook for showing how the program works and generated the README.md, you should adjust this\nMANIFEST.in # This determines what files outside of .py files are included in the package, you may need to adjust it.\nREADME.md\nsetup.py # This is the file that tells pip how to install the package, you shouldn't need to edit this ever\nstyles.css\n\nIf you want to check what you’re documentation looks like run nbdev_preview in command line of the project folder\n\n\nLibraries\nHere we include all the libraries of this module. You can see they’re sectioned so the top parts can be easy cut and paste into new files.\nNormally your imports go into Project specific libraries above, but we’ll put it in a code block here. In this example you’ll want to comment out the code below, because YOUR_REPO_NAME changes with each repository, it’ll cause issues if you try to run it with a different repository name\nBecause the notebooks now are located in the nbs folder, we need to change the python wd for the notebook to the project folder. Keep this included in all notebooks but don’t export it to the package.\n\n# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\nos.chdir(core.PROJECT_DIR)\n\nNow you have access to your functions in core.py and call call them here.\nNOTE: if you change another notebook, run nbdev_prepare, and restart your current kernel to see the changes\nHere we’ll load the config file values, note that the file isn’t exported so is for development and documentation purposes.\n\nA note on config files: The final package should only contain config.default.* files. These files are located in package dir PACKAGE_DIR/config. For development, custom config files can be specified in the project dir PROJECT_DIR/config/ folder. These files will not be shipped with the package, but for development, they can be accessed from the project dir (thanks to to code above), which usually is your working directory in terminal while developping.\n\n\nconfig = core.get_config()  # This will load the .env file and print the config\n\nLets look at our values, as we have a dictionary, that can be viewed more nicely as a json object\n\n# print the config as a json string\nprint(json.dumps(config, indent=4))\n\nLets make our own hello_world that’s a bit different from the test in core. It take’s two names! This is exported so it goes into our module, meaning it can be refernced with template_nbdev_example.hello_world\n\nsource\n\nhello_world\n\n hello_world (name1:str, name2:str)\n\nNow lets also make a function thats intended to call from the command line. As we intend that make sure you get your config variables and handle them properly!\n\nsource\n\n\ncli\n\n cli (name:str=None, alternative_name:str=None, config_file:str=None)\n\nThis will print Hello World! with your name\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\nNone\nA name\n\n\nalternative_name\nstr\nNone\nAn alternative name\n\n\nconfig_file\nstr\nNone\nconfig file to set env vars from\n\n\nReturns\nNone\n\n\n\n\n\nSo now that it exists lets add it to our settings.ini, the console_scripts section. We have already edited the file for you, it should look like this (replace name of your repo with whatever you called this repository when you initized it):\nconsole_scripts =\n    hello_world=&lt;name of your repo&gt;.hello_world:cli\nFor a new console-script, you’ll need to run nbdev_prepare to turn this into a module and gain access to your new commands, if your commands aren’t showing up ensure you’ve run python -m pip install -e '.[dev]' in your ./venv\nThe ! lets you run on the command line, so the following block only works if everything above is successful. Remember to restart your kernel if you make changes to the module.\n\n!hello_world\n\nWith some different values\n\n!hello_world --name \"John\" --alternative_name \"Jane\"\n\nTry using an alternative config as well\n\n!hello_world --config_file \"./config.default.env\"\n\nNice, you can also run these through the notebook as a function\n\ncli(name=\"John\", alternative_name=\"Jane\", config_file=\"./config.default.env\")\n\nLets add a test here as well, which will get run through ./.github/workflows/test.yaml whenever changes happen to the repository\n\ntest.test_eq(\n    None,\n    cli(name=\"John\", alternative_name=\"Jane\", config_file=\"./config.default.env\"),\n)\n\nIf you’re on the default config.default.env and config.default.yaml you’ll see at the bottom: “example.input.name”: “Kim”, “example.input.alternative_name”: “Lee” I encourage you to adjust these values to get familiar with the config files\nThat’s the demo for now, feel free to create issues if you have suggestions to add.",
    "crumbs": [
      "Additional Learning Resources"
    ]
  },
  {
    "objectID": "spyogenes_parser.html",
    "href": "spyogenes_parser.html",
    "title": "Directive for creating a script for your notebook",
    "section": "",
    "text": "Include all the libraries which should be used in this module. You can also import modules from other notebooks; here, we have imported the functions in the core notebook.\n\n# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\nos.chdir(core.PROJECT_DIR)",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "spyogenes_parser.html#testing",
    "href": "spyogenes_parser.html#testing",
    "title": "Directive for creating a script for your notebook",
    "section": "TESTING",
    "text": "TESTING\n\nemm_typing_dict = extract_emm_type(emm_blast_tsv=\"test_input/Spyogenes/emm_typing/test1.emm.blast.tsv\")\n\nassert(emm_typing_dict[\"EMM_type\"] == \"EMM87.0\")\nassert(emm_typing_dict[\"ENN_type\"] == \"EMM159.0*\")\nassert(emm_typing_dict[\"MRP_type\"] == \"-\")\nassert(emm_typing_dict[\"emm_typing_notes\"] == \"ENN159.0 with pident 97.78 and length 180/180\")\n\n\n\nSpyogenes_results = SpyogenesResults.from_tool_paths(emm_blast_tsv=\"test_input/Spyogenes/emm_typing/test2.emm.blast.tsv\", sample_name=\"test_sample\")\n\nassert(list(Spyogenes_results.results_dict.keys())[0] == \"test_sample\")\n\nSpyogenes_results = SpyogenesResults.from_tool_paths_dict(file_paths=  {\"sample_3\": {\"emm_results\": \"test_input/Spyogenes/emm_typing/test3.emm.blast.tsv\"},\n                                                                        \"sample_4\": {\"emm_results\": \"test_input/Spyogenes/emm_typing/test4.emm.blast.tsv\"}})\n\nassert(Spyogenes_results.results_dict[\"sample_3\"][\"EMM_type\"] == \"EMM77.0\")\nassert(Spyogenes_results.results_dict[\"sample_3\"][\"ENN_type\"] == \"EMM159.0\")\nassert(Spyogenes_results.results_dict[\"sample_3\"][\"MRP_type\"] == \"EMM141.3*\")\nassert(Spyogenes_results.results_dict[\"sample_3\"][\"emm_typing_notes\"] == \"MRP141.3 with pident 97.22 and length 180/180\")\n\n\n\nassert(Spyogenes_results.results_df[\"EMM_type\"][\"sample_4\"] == \"EMM13.0\")\nassert(Spyogenes_results.results_df[\"ENN_type\"][\"sample_4\"] == \"EMM203.4*\")\nassert(Spyogenes_results.results_df[\"MRP_type\"][\"sample_4\"] == \"EMM141.4\")\nassert(Spyogenes_results.results_df[\"emm_typing_notes\"][\"sample_4\"] == \"ENN203.4 with pident 97.22 and length 180/180\")\n\n\nSpyogenes_results = SpyogenesResults.from_tool_paths_tsv(tool_paths_tsv=\"test_input/Spyogenes/batch_parser_file_paths.tsv\")\n\n\nassert(Spyogenes_results.results_dict[\"sample_5\"][\"EMM_type\"] == \"EMM81.0\")\nassert(Spyogenes_results.results_dict[\"sample_5\"][\"ENN_type\"] == \"-\")\nassert(Spyogenes_results.results_dict[\"sample_5\"][\"MRP_type\"] == \"EMM156.4*\")\nassert(Spyogenes_results.results_dict[\"sample_5\"][\"emm_typing_notes\"] == \"EMM156.4 with pident 99.44 and length 180/180, EMM redesignated due to known MRP+EMM operon\")\n\n\nassert(Spyogenes_results.results_df[\"EMM_type\"][\"sample_7\"] == \"-\")\nassert(Spyogenes_results.results_df[\"ENN_type\"][\"sample_7\"] == \"-\")\nassert(Spyogenes_results.results_df[\"MRP_type\"][\"sample_7\"] == \"-\")\nassert(Spyogenes_results.results_df[\"emm_typing_notes\"][\"sample_7\"] == \"EMM and EMM-like genes found on multiple contigs. Alleles found: 203.4*/28.0\")\n\nassert(Spyogenes_results.results_df[\"EMM_type\"][\"sample_empty\"] == \"-\")\nassert(Spyogenes_results.results_df[\"ENN_type\"][\"sample_empty\"] == \"-\")\nassert(Spyogenes_results.results_df[\"MRP_type\"][\"sample_empty\"] == \"-\")\nassert(Spyogenes_results.results_df[\"emm_typing_notes\"][\"sample_empty\"] == \"Empty blast output, no EMM genes detected\")\n\n\nassert(Spyogenes_results.results_df[\"EMM_type\"][\"sample_nonexist\"] == \"-\")\nassert(Spyogenes_results.results_df[\"ENN_type\"][\"sample_nonexist\"] == \"-\")\nassert(Spyogenes_results.results_df[\"MRP_type\"][\"sample_nonexist\"] == \"-\")\nassert(Spyogenes_results.results_df[\"emm_typing_notes\"][\"sample_nonexist\"] == \"No blast output found for EMM genes\")\n\n\nsource\n\nSpyogenes_batch_parser\n\n Spyogenes_batch_parser (file_path_tsv:pathlib.Path=None,\n                         output_file:pathlib.Path=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path_tsv\nPath\nNone\nPath to tsv containing file paths to the outputs from tools to be parsed. Must contain headers “sample_name”, “sbt_results”, and “lag1_blast_results”\n\n\noutput_file\nPath\nNone\nPath to output tsv\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nSpyogenes_parser\n\n Spyogenes_parser (emm_blast_tsv:pathlib.Path=None,\n                   output_file:pathlib.Path=None, sample_name:str=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nemm_blast_tsv\nPath\nNone\nBlast output from blasting EMM and emm-like genes\n\n\noutput_file\nPath\nNone\nPath to output tsv\n\n\nsample_name\nstr\nNone\n\n\n\nReturns\nNone",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "nmeningitidis_parser.html",
    "href": "nmeningitidis_parser.html",
    "title": "Directive for creating a script for your notebook",
    "section": "",
    "text": "Include all the libraries which should be used in this module. You can also import modules from other notebooks; here, we have imported the functions in the core notebook.\n\n# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\nos.chdir(core.PROJECT_DIR)",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "nmeningitidis_parser.html#testing",
    "href": "nmeningitidis_parser.html#testing",
    "title": "Directive for creating a script for your notebook",
    "section": "TESTING",
    "text": "TESTING\n\nmeningotype_results = extract_meningotype(meningotype_tsv=Path(\"test_input/Nmeningitidis/meningotype/meningotype1.tsv\"))\n\nassert(meningotype_results[\"SEROGROUP\"] == \"Y\")\nassert(meningotype_results[\"VR1\"] == \"21\")\nassert(meningotype_results[\"VR2\"] == \"16\")\nassert(meningotype_results[\"FetA\"] == \"F3-7\")\n\ncc_results = extract_cc_from_mlst(\"1157\",Path(\"test_input/Nmeningitidis/neisseria_mlst_scheme.tsv\"))\ncc_results = extract_cc_from_mlst(\"11\",Path(\"test_input/Nmeningitidis/neisseria_mlst_scheme.tsv\"))\n\n\n\n\nf = NmeningitidisResults.from_tool_paths_dict(file_paths=  {\"sample_1\": {\"meningotype_results\": \"test_input/Nmeningitidis/meningotype/meningotype1.tsv\", \"MLST\": \"1466\", \"mlst_scheme_tsv\": \"test_input/Nmeningitidis/neisseria_mlst_scheme.tsv\"},\n                                                            \"sample_2\": {\"meningotype_results\": \"test_input/Nmeningitidis/meningotype/meningotype2.tsv\", \"MLST\": \"1157\", \"mlst_scheme_tsv\": \"test_input/Nmeningitidis/neisseria_mlst_scheme.tsv\"}\n                                                            })\n\nassert(f.results_df[\"SEROGROUP\"][\"sample_1\"] == \"Y\")\nassert(f.results_df[\"VR1\"][\"sample_1\"] == \"21\")\nassert(f.results_df[\"CC\"][\"sample_1\"] == \"174\")\nassert(f.results_df[\"SEROGROUP\"][\"sample_2\"] == \"X\")\nassert(f.results_df[\"VR2\"][\"sample_2\"] == \"2-67\")\nassert(f.results_df[\"CC\"][\"sample_2\"] == \"1157\")\n\nf = NmeningitidisResults.from_tool_paths_tsv(tool_paths_tsv=Path(\"test_input/Nmeningitidis/batch_parser_file_paths.tsv\"))\n\nprint(f.results_df)\n\n         SEROGROUP   VR1   VR2   FetA    CC\nsample_1         Y    21    16   F3-7   174\nsample_2         X     5  2-67  F5-36  1157\nsample_3         B  18-1  30-4   F3-3      \nsample_4       NaN   NaN   NaN    NaN      \nsample_5       NaN   NaN   NaN    NaN      \n\n\nNo meningotype output found at test_input/Nmeningitidis/meningotype/meningotype4.tsv\nMeningotype output file empty at test_input/empty_file.txt\n\n\n\nsource\n\nNmeningitidis_batch_parser\n\n Nmeningitidis_batch_parser (file_path_tsv:pathlib.Path=None,\n                             output_file:pathlib.Path=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path_tsv\nPath\nNone\nPath to tsv containing file paths to the outputs from tools to be parsed. Must contain headers “sample_name”, “sbt_results”, and “lag1_blast_results”\n\n\noutput_file\nPath\nNone\nPath to output tsv\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nNmeningitidis_parser\n\n Nmeningitidis_parser (meningotype_tsv:pathlib.Path=None, MLST:str=None,\n                       mlst_scheme_tsv:pathlib.Path=None,\n                       sample_name:str=None,\n                       output_file:pathlib.Path=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmeningotype_tsv\nPath\nNone\nBlast output from blasting EMM and emm-like genes\n\n\nMLST\nstr\nNone\nMLST to deduce Clonal complex from\n\n\nmlst_scheme_tsv\nPath\nNone\nPath to pubmlst scheme for neisseria for MLST: CC table\n\n\nsample_name\nstr\nNone\n\n\n\noutput_file\nPath\nNone\n\n\n\nReturns\nNone",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ssi_analysis_result_parsers",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "ssi_analysis_result_parsers"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "ssi_analysis_result_parsers",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall ssi_analysis_result_parsers in Development mode\n# make sure ssi_analysis_result_parsers package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to ssi_analysis_result_parsers\n$ nbdev_prepare",
    "crumbs": [
      "ssi_analysis_result_parsers"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "ssi_analysis_result_parsers",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/$GIT_USER_NAME/ssi_analysis_result_parsers.git\nor from conda\n$ conda install -c $GIT_USER_NAME ssi_analysis_result_parsers\nor from pypi\n$ pip install ssi_analysis_result_parsers\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines on conda and pypi respectively.",
    "crumbs": [
      "ssi_analysis_result_parsers"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "ssi_analysis_result_parsers",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2",
    "crumbs": [
      "ssi_analysis_result_parsers"
    ]
  },
  {
    "objectID": "blast_parser.html",
    "href": "blast_parser.html",
    "title": "Directive for creating a script for your notebook",
    "section": "",
    "text": "Include all the libraries which should be used in this module. You can also import modules from other notebooks; here, we have imported the functions in the core notebook.\n\n# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\nos.chdir(core.PROJECT_DIR)",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "blast_parser.html#testing",
    "href": "blast_parser.html#testing",
    "title": "Directive for creating a script for your notebook",
    "section": "TESTING",
    "text": "TESTING\n\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/blast_parser/gene_presence_absence_test.tsv\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=False,\n                                     hits_as_string=True\n                                     )\nassert(len(gene_presence_dict) == 1)\nassert(gene_presence_dict[\"genes_found\"] == \"asd, proA\")\n\n\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/blast_parser/gene_presence_absence_test.tsv\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=True,\n                                     hits_as_string=True,\n                                     )\nassert(gene_presence_dict[\"genes_found\"] == \"asd__98.732__100.0, proA__97.284__100.0\")\n\n\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/blast_parser/gene_presence_absence_test.tsv\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=True,\n                                     hits_as_string=True,\n                                     pident_threshold=80,\n                                     )\nassert(gene_presence_dict[\"genes_found\"] == \"asd__98.732__100.0, pilE__82.835__100.0, proA__97.284__100.0\")\n\n\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/blast_parser/gene_presence_absence_test.tsv\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=False,\n                                     hits_as_string=False,\n                                     gene_names = [\"asd\",\"proA\",\"pilE\"])\nassert(gene_presence_dict[\"asd\"] == \"1\")\nassert(gene_presence_dict[\"proA\"] == \"1\")\nassert(gene_presence_dict[\"pilE\"] == \"0\")\n\n\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/blast_parser/gene_presence_absence_test.tsv\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=True,\n                                     hits_as_string=False,\n                                     gene_names = [\"asd\",\"proA\",\"pilE\"])\n\nassert(gene_presence_dict[\"asd\"] == \"98.732__100.0\")\nassert(gene_presence_dict[\"proA\"] == \"97.284__100.0\")\nassert(gene_presence_dict[\"pilE\"] == \"0\")\n\n\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/blast_parser/empty_gene_presence_absense_test.tsv\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=False,\n                                     hits_as_string=False,\n                                     gene_names=[\"lag-1\"]\n                                     )\nassert(gene_presence_dict[\"lag-1\"] == \"0\")\n\n\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/empty_file.txt\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=False,\n                                     hits_as_string=False,\n                                     gene_names=[\"lag-1\"]\n                                     )\nassert(gene_presence_dict[\"lag-1\"] == \"0\")\n\n\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/empty_file.txt\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=True,\n                                     hits_as_string=False,\n                                     gene_names=[\"lag-1\"]\n                                     )\nassert(gene_presence_dict[\"lag-1\"] == \"0\")\n\n\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/empty_file.txt\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=False,\n                                     hits_as_string=True,\n                                     gene_names=[\"lag-1\"]\n                                     )\nassert(gene_presence_dict[\"genes_found\"] == \"\")\n\n\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/empty_file.txt\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=True,\n                                     hits_as_string=True\n                                     )\nassert(gene_presence_dict[\"genes_found\"] == \"\")\n\n\n# Test for missing file handling (should return None)\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/file/that/does/not/exist.tsv\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=True,\n                                     hits_as_string=True,\n                                     gene_names=[\"lag-1\"]\n                                     )\nassert(gene_presence_dict is None)\n\n# Check for incorrect number of columns handling (should return None)\ngene_presence_dict = extract_presence_absence(blast_output_tsv=\"./test_input/Legionella/test.sbt.tsv\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=True,\n                                     hits_as_string=True,\n                                     gene_names=[\"lag-1\"]\n                                     )\nassert(gene_presence_dict is None)\n\n\nallele_dict = extract_allele_matches(blast_output_tsv=\"./test_input/blast_parser/allele_matches_test.tsv\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\")\n\ndetailed_allele_dict = extract_allele_matches(blast_output_tsv=\"./test_input/blast_parser/allele_matches_test.tsv\",\n                                     tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                     include_match_stats=True)\n\nassert(len(allele_dict) == 7)\nassert(allele_dict['asd'] == \"9\")\nassert(detailed_allele_dict['pilE'] == \"3__100.0__100.0\")\n\n\n# Test for missing file handling (should return None)\nallele_dict = extract_allele_matches(blast_output_tsv=\"./test_input/file/that/does/not/exist.tsv\",\n                                            tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                            include_match_stats=True)\nassert(allele_dict is None)\n\n\n# Test for incorrect number of columns handling (should return None)\nallele_dict = extract_allele_matches(blast_output_tsv=\"./test_input/Legionella/test.sbt.tsv\",\n                                            tsv_header=\"qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\",\n                                            include_match_stats=True)\nassert(allele_dict is None)\n\nBlast output file ./test_input/blast_parser/empty_gene_presence_absense_test.tsv empty. Assuming 0 blast hits.\nBlast output file ./test_input/empty_file.txt empty. Assuming 0 blast hits.\nBlast output file ./test_input/empty_file.txt empty. Assuming 0 blast hits.\nBlast output file ./test_input/empty_file.txt empty. Assuming 0 blast hits.\nBlast output file ./test_input/empty_file.txt empty. Assuming 0 blast hits.\n\n\nNo blast output found at ./test_input/file/that/does/not/exist.tsv\nFailed to parse ./test_input/Legionella/test.sbt.tsv. Number of columns do not match length of provided header string\nNo blast output found at ./test_input/file/that/does/not/exist.tsv\nFailed to parse ./test_input/Legionella/test.sbt.tsv. Number of columns do not match length of provided header string\n\n\n\nsource\n\nallele_matches\n\n allele_matches (blast_output:pathlib.Path=None,\n                 blast_tsv_header:str='qseqid sseqid pident length qlen\n                 qstart qend sstart send sseq evalue bitscore',\n                 include_match_stats:bool=False,\n                 output_file:pathlib.Path=None, config_file:str=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nblast_output\nPath\nNone\nPath to blast output file. Generated with –outfmt 6 option\n\n\nblast_tsv_header\nstr\nqseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\nheaders in blast output\n\n\ninclude_match_stats\nbool\nFalse\nTrue to include percent identity and percent length in output, false to only include allele number\n\n\noutput_file\nPath\nNone\n\n\n\nconfig_file\nstr\nNone\nconfig file to set env vars from\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\npresence_absence\n\n presence_absence (blast_output:pathlib.Path=None,\n                   blast_tsv_header:str='qseqid sseqid pident length qlen\n                   qstart qend sstart send sseq evalue bitscore',\n                   hits_as_string:bool=True,\n                   include_match_stats:bool=False,\n                   percent_identityt:float=90, percent_length:float=60,\n                   gene_names:list=None, output_file:pathlib.Path=None,\n                   config_file:str=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nblast_output\nPath\nNone\nPath to blast output file. Generated with –outfmt 6 option\n\n\nblast_tsv_header\nstr\nqseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\nheaders in blast output\n\n\nhits_as_string\nbool\nTrue\nTrue to print a comma separated list of found genes on a single line. False to return a key: value pair for each gene\n\n\ninclude_match_stats\nbool\nFalse\nTrue to include percent identity and percent length in output, false to only include present/absent\n\n\npercent_identityt\nfloat\n90\npercent identity threshold for considering a gene present\n\n\npercent_length\nfloat\n60\npercent length threshold for considering a gene present\n\n\ngene_names\nlist\nNone\nname of genes to look for when hits_as_string = False\n\n\noutput_file\nPath\nNone\n\n\n\nconfig_file\nstr\nNone\nconfig file to set env vars from\n\n\nReturns\nNone",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Global static vars",
    "section": "",
    "text": "For help with the Markdown language, see this guide.",
    "crumbs": [
      "Global static vars"
    ]
  },
  {
    "objectID": "core.html#libraries",
    "href": "core.html#libraries",
    "title": "Global static vars",
    "section": "Libraries",
    "text": "Libraries\nCurrently all libraries included are listed at the top and calls to them are also made in the block of code that uses them. This is for readability and the performance hit of the import is negligible.",
    "crumbs": [
      "Global static vars"
    ]
  },
  {
    "objectID": "core.html#config",
    "href": "core.html#config",
    "title": "Global static vars",
    "section": "Config",
    "text": "Config\nOur config file holds all program and user specific variables. This is a good practice to follow as it allows us to easily change variables without having to change code. It also allows us to easily change variables based on the environment we are running in. For example, we may want to run a program in a test environment with a different database than we would in production. This is also a good practice to follow as it allows us to easily change variables without having to change code. It also allows us to easily change variables based on the environment we are running in. For example, we may want to run a program in a test environment with a different database than we would in production.\nConfiguration is templated to rely on environment (ENV) variables. A default ENV config is provided in ./config/config.default.env and more advanced data structures are supported in ./config/config.default.yaml. The .yaml file is meant to represent what your program actually works with and the .env file options the user can change at run time.\nMake sure you know the priority of variables and check on them when debugging your code. Also ensure that your yaml file is referenced appropriately in the .env file.\nWhen in use there’s an expectation you’ll have multiple config files for different use cases e.g. development, production environment for different paths, etc.\n\nset env variables\nA helper function for getting your config values, this will set the environment variables with the provided .env values. If you’re missing values it’ll ensure they’re loaded in with the defaults file.\n\nsource\n\n\nset_env_variables\n\n set_env_variables (config_path:str, overide_env_vars:bool=True)\n\n\n\nget config\nWhen you run this function, assuming things are set up properly, you end up with a dict that matches your .yaml file. This file will have all the inputs for the package and settings of your program.\nTo do this it will use a .env config file, which has an associated yaml file defined with CORE_YAML_CONFIG_FILE in the .env file. And then use the .env file to load values into the associated .yaml file.\n\nsource\n\n\nget_config\n\n get_config (config_path:str=None, overide_env_vars:bool=True)\n\n\n\nVariables\nAll the user input variables and machine adjustable variables should be in your config, which is a dict. Reference config.default.yaml for how to access your variables. Also note that with python dicts you can use dict_variable.get(\"variable\", default_value) to ensure that you don’t get a key error if the variable is not set.\n\n\nshow project env vars\nA helper function intended to only be used with debugging. It shows all your project specific environmental variables.\n\nsource\n\n\nshow_project_env_vars\n\n show_project_env_vars (config:dict)",
    "crumbs": [
      "Global static vars"
    ]
  },
  {
    "objectID": "core.html#get_samplesheet",
    "href": "core.html#get_samplesheet",
    "title": "Global static vars",
    "section": "get_samplesheet",
    "text": "get_samplesheet\nThis function is to unify the way we work with sample_sheet’s which is for us a file with a table of values, typically samples for batch processing. We want to approach doing it this way so all programs have batch processing in mind and working with the same data structure.\nTo make use of it we have a small sample_sheet yaml object which looks like\nsample_sheet:\n    path: path/to/sample_sheet.tsv\n    delimiter: '\\t' # Optional, will assume , for csv and \\t otherwises\n    header: 0 # Optional, 0 indicates first row is header, None indicates no header\n    columns: ['column1', 'column2', 'column3'] # Optional, if not provided all columns will be used\nMake sure to add that to your relevant section in your config (can be multiple times if you’re working with different sheets or different columns), then call the function on this object and it’ll either mention somethings wrong or return a pandas dataframe with the columns of interest.\nThis is an example of a common sample_sheet we work with. We will ingest the hash at the beginning so it doesn’t affect column naming. Extra empty rows at the end are also stripped.\n#sample_id  file_path   metadata1   metadata2\nSample1 /path/to/sample1.fasta  value1  option1\nSample2 /path/to/sample2.fasta  value2  option2\nSample3 /path/to/sample3.fasta  value3  option1\nSample4 /path/to/sample4.fasta  value1  option2\nSample5 /path/to/sample5.fasta  value2  option1\n\n# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\nos.chdir(PROJECT_DIR)\n\n\nsource\n\nget_samplesheet\n\n get_samplesheet (sample_sheet_config:dict)\n\n\nsource\n\n\nprint_results_dict_to_tsv\n\n print_results_dict_to_tsv (results_dict:dict, output_file:pathlib.Path,\n                            sample_name:str=None)\n\n\nsource\n\n\nupdate_results_dict\n\n update_results_dict (old_results:dict, new_results:dict,\n                      old_duplicate_key_prefix:str=None,\n                      new_duplicate_key_prefix:str=None)\n\n\nsource\n\n\nPipelineResults\n\n PipelineResults (results_dict)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n### Make sure results dict are updated properly\nassert(update_results_dict({\"a\": 1, \"b\": 2}, {\"b\":5,\"c\":7}, new_duplicate_key_prefix=\"new: \")[\"new: b\"] == 5)\nassert(update_results_dict({\"a\": 1, \"b\": 2}, {\"b\":5,\"c\":7}, old_duplicate_key_prefix=\"old: \")[\"old: b\"] == 2)\nassert(update_results_dict({\"a\": 1, \"b\": 2}, {\"b\":5,\"c\":7}, new_duplicate_key_prefix=\"new: \", old_duplicate_key_prefix=\"old: \")[\"a\"] == 1)\nassert(update_results_dict({\"a\": 1, \"b\": 2}, {\"b\":5,\"c\":7}, new_duplicate_key_prefix=\"new: \", old_duplicate_key_prefix=\"old: \")[\"new: b\"] == 5)\nassert(update_results_dict({\"a\": 1, \"b\": 2}, {\"b\":5,\"c\":7}, new_duplicate_key_prefix=\"new: \", old_duplicate_key_prefix=\"old: \")[\"old: b\"] == 2)\n\n\n\n### Make sure results dicts are printed correctly to file\nprint_dict = update_results_dict({\"a\": \"1\", \"b\": \"2\"}, {\"b\": \"5\",\"c\": \"7\"}, new_duplicate_key_prefix=\"new: \")\n\n\ntest_output_path = \"./test_output/output.tsv\"\nprint_results_dict_to_tsv(print_dict, test_output_path)\nh256 = sha256()\nh256.update(open(test_output_path,\"rb\").read())\nassert(h256.hexdigest() == \"95010ad49667c28a25bb80bb450290e5f7286c7eeb3220ff795c9fecf1326ce1\")\nos.remove(\"./test_output/output.tsv\")\n\n\n\ntest_output_path = \"./test_output/output_with_sample_name.tsv\"\nprint_results_dict_to_tsv(print_dict, \"./test_output/output_with_sample_name.tsv\", \"sample1\")\nh256 = sha256()\nh256.update(open(test_output_path,\"rb\").read())\nassert(h256.hexdigest() == \"3501bb59ac5ccee5820ac5f66bd314c42098a5bb808abcfd830d3c38b744754a\")",
    "crumbs": [
      "Global static vars"
    ]
  },
  {
    "objectID": "hinfluenzae_parser.html",
    "href": "hinfluenzae_parser.html",
    "title": "Directive for creating a script for your notebook",
    "section": "",
    "text": "Include all the libraries which should be used in this module. You can also import modules from other notebooks; here, we have imported the functions in the core notebook.\n\n# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\nos.chdir(core.PROJECT_DIR)",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  },
  {
    "objectID": "hinfluenzae_parser.html#testing",
    "href": "hinfluenzae_parser.html#testing",
    "title": "Directive for creating a script for your notebook",
    "section": "TESTING",
    "text": "TESTING\n\nsource\n\nHinfluenzae_batch_parser\n\n Hinfluenzae_batch_parser (file_path_tsv:pathlib.Path=None,\n                           output_file:pathlib.Path=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path_tsv\nPath\nNone\nPath to tsv containing file paths to the outputs from tools to be parsed. Must contain headers “sample_name”, “sbt_results”, and “lag1_blast_results”\n\n\noutput_file\nPath\nNone\nPath to output tsv\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nHinfluenzae_parser\n\n Hinfluenzae_parser (ftsI_ariba_tsv:pathlib.Path=None,\n                     hicap_tsv:pathlib.Path=None,\n                     biotype_blast_tsv:pathlib.Path=None,\n                     ftsI_types_tsv:pathlib.Path=None,\n                     output_file:pathlib.Path=None, sample_name:str=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nftsI_ariba_tsv\nPath\nNone\nPath to report.tsv from ftsI ariba output\n\n\nhicap_tsv\nPath\nNone\nPath to hicap tsv output\n\n\nbiotype_blast_tsv\nPath\nNone\nPath to output from biotype gene blast. Generated with blastn -query biotype_genes.fasta -subject assembly.fasta -outfmt “6 qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore”\n\n\nftsI_types_tsv\nPath\nNone\nPath to table to convert ftsI snps to ftsI types\n\n\noutput_file\nPath\nNone\nPath to output tsv\n\n\nsample_name\nstr\nNone\n\n\n\nReturns\nNone",
    "crumbs": [
      "Directive for creating a script for your notebook"
    ]
  }
]