{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directive for creating a script for your notebook\n",
    "\n",
    "The block here below is required at the top of each notebook that you want to create a script for. You will also need to edit the \"settings.ini\" file, to create a script (see [Coding in NBdev](https://dksund.sharepoint.com/:fl:/g/contentstorage/CSP_7c761ee7-b577-4e08-8517-bc82392bf65e/ETlSfUyArSNJhX8veMI_JQ8By1aXGHzDJkhotpfpXx4mmw?e=037EwH&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF83Yzc2MWVlNy1iNTc3LTRlMDgtODUxNy1iYzgyMzkyYmY2NWUmZD1iJTIxNXg1MmZIZTFDRTZGRjd5Q09TdjJYblkwVlNiWXFYcE1yaHVrVmZqTVJUVEE4X1VwZjhTd1JxcjRNdmFrSmh2RCZmPTAxVlVLVzVWSlpLSjZVWkFGTkVORVlLN1pQUERCRDZKSVAmYz0lMkYmYT1Mb29wQXBwJnA9JTQwZmx1aWR4JTJGbG9vcC1wYWdlLWNvbnRhaW5lciZ4PSU3QiUyMnclMjIlM0ElMjJUMFJUVUh4a2EzTjFibVF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUUxZURVeVpraGxNVU5GTmtaR04zbERUMU4yTWxodVdUQldVMkpaY1Zod1RYSm9kV3RXWm1wTlVsUlVRVGhmVlhCbU9GTjNVbkZ5TkUxMllXdEthSFpFZkRBeFZsVkxWelZXU1RJMVJsaFBNalkyUlZkQ1FqTTFRVmhKVTBkRFVVcFdXa1klM0QlMjIlMkMlMjJpJTIyJTNBJTIyNzRmNzM1ZmUtYzg4Ny00MjhhLWFkZmYtNTEyZTg2YmNmZmQzJTIyJTdE) \n",
    "(**Writing your own notebooks**) on loop for more details). Replace **some_string** with a name that makes sense for your notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Ecoli_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "Include all the libraries which should be used in this *Escherichia coli* module, to create log the various operations to load input files, craete datastructures, maniplate and output desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime \n",
    "from typing import List, Dict \n",
    "from fastcore.script import call_parse\n",
    "#import functions from core module (optional, but most likely needed). \n",
    "from ssi_analysis_result_parsers import(\n",
    "    core\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\n",
    "os.chdir(core.PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Necessary functins to extract *k-mer alignment (KMA tool)* results from *.res* files to perform following steps\n",
    "\n",
    "- Extract data \n",
    "- Filter data based on gene-specific thresholds for the *template coverage* and *Query identity*\n",
    "- Perform *OH* typing and *stx* detection based on gene-specific information\n",
    "- Wrangle data using *pandas* dataframes creating accurate data structure\n",
    "- Store results in either sample-specific output files or one full tsv file extending the original samplesheet information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "thresholds = {\n",
    "    \"stx\": [98, 98],\n",
    "    \"wzx\": [98, 98],\n",
    "    \"wzy\": [98, 98],\n",
    "    \"wzt\": [98, 98],\n",
    "    \"wzm\": [98, 98],\n",
    "    \"fliC\": [90, 90],\n",
    "    \"fli\": [90, 90],\n",
    "    \"eae\": [95, 95],\n",
    "    \"ehxA\": [95, 95],\n",
    "    \"other\": [98, 98]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds\n",
    "\n",
    "Defines gene-specific tresholds used to filter the input *KMA .res* files on the columns [*template coverage*,*Query identity*] to identify genes related to:\n",
    "- Shiga Toxin (stx1 and stx2 subtypes)\n",
    "- Serotyping using O-antigens with Serotype genes (wzx,wzy,wzt,wzm) and H-antigen using Flagellar genes (fli & fliC)\n",
    "- Surface adhesion for EPEC and STEC strains with eae gene \n",
    "- Hemolytic toxin (ehxA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging\n",
    "\n",
    "Defines a logging setup function used throughout the later functions to record information and errors both to a per-sample log file. \n",
    "\n",
    "The log file is created inside the specified log directory with a filename based on the sample name. The log file contains detailed messages with information of the progression, errors and warnings with timestamps. Which is useful for tracing execution and diagnosing issues per sample in multi-sample pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def setup_logging(log_dir: str, sample_name: str) -> None:\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file = os.path.join(log_dir, f\"{sample_name}_kma_fbi.log\")\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    while logger.hasHandlers():\n",
    "        logger.removeHandler(logger.handlers[0])\n",
    "\n",
    "    logging.basicConfig(\n",
    "        filename=log_file,\n",
    "        filemode=\"a\",\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        level=logging.INFO\n",
    "    )\n",
    "\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    logging.info(f\"Logging started for {log_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds filtering & .res parsing\n",
    "\n",
    "For each gene specified earlier, the thresholds for the template coverage and query identity is extracted and used to filter the input *KMA .res* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_threshold(template_name: str, thresholds: Dict[str, List[int]]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Returns the coverage and identity threshold for a given gene.\n",
    "\n",
    "    Args:\n",
    "        template_name (str): Name of the template (gene) from the .res file.\n",
    "        thresholds (Dict[str, List[int]]): Dictionary of gene thresholds.\n",
    "\n",
    "    Returns:\n",
    "        List[int]: A list of two integers: [coverage_threshold, identity_threshold].\n",
    "    \"\"\"\n",
    "    for key in thresholds:\n",
    "        if key in template_name:\n",
    "            return thresholds[key]\n",
    "    return thresholds[\"other\"]\n",
    "\n",
    "def process_res_file(res_file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads and filters a KMA .res file based on predefined thresholds.\n",
    "\n",
    "    Args:\n",
    "        res_file_path (str): Path to the .res file.\n",
    "        thresholds (Dict[str, List[int]]): Gene-specific thresholds.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered results DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        res_df = pd.read_csv(res_file_path, sep=\"\\t\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File not found: {res_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(f\"File is empty or not properly formatted: {res_file_path}\")\n",
    "\n",
    "    required_columns = {\"#Template\", \"Template_Coverage\", \"Query_Identity\", \"Depth\"}\n",
    "    if not required_columns.issubset(res_df.columns):\n",
    "        raise ValueError(f\"Missing expected columns in {res_file_path}\")\n",
    "\n",
    "    res_df[\"threshold\"] = res_df[\"#Template\"].apply(lambda x: get_threshold(x, thresholds))\n",
    "    res_df_filtered = res_df[\n",
    "        (res_df[\"Template_Coverage\"] >= res_df[\"threshold\"].apply(lambda x: x[0])) &\n",
    "        (res_df[\"Query_Identity\"] >= res_df[\"threshold\"].apply(lambda x: x[1]))\n",
    "    ]\n",
    "    return res_df_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escherichia coli results\n",
    "\n",
    "Defines a class to parse, summarize and export the *E. coli* gene typing results from the filtered .res input files. \n",
    "It creates per-sample logging and outputs the results either pr sample in their respective directories with all input files or as one conjoined file extending the input samplesheet file. The class allows for an additional column in the final output with a more detailed and summarize gene-specific information of the Depth,template coverage, query identity.\n",
    "\n",
    "With the final output with verbose option having the following structure\n",
    "\n",
    "| sample_name | illumina_read_files | nanopore_read_file | assembly_file | organism | variant | notes | stx | OH | wzx | wzy | wzt | wzm | eae | ehxA | Other | verbose|\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "\n",
    "The Serotyping results in the above structure has gene-specific requirements.\n",
    "\n",
    "- If *wzx* and *wzy* are the sole O-antigen genes with no conflicts between them, that information is used as the O-type result and stored in the *OH* column, otherwise the results are store in the *wzx* and *wzy* columns and O-type in the *OH* column remains empty \n",
    "- If *wzt* and *wzm* are the sole O-antigen genes with no conflicts between them, that information is used as the O-type result and stored in the *OH* column, otherwise the results are store in the *wzt* and *wzm* columns and O-type in the *OH* column remains empty  \n",
    "- If all O-antigen genes exist in the *KMA* results, the O-type in the *OH* column remains empty and all four *wzx,wzy,wzt,wzm* columns are filled\n",
    "- If *fli* exist in the *KMA* results that information is used as the H-type and stored in the *OH* column. The only scenario where *fliC* is used to determine the H-type and stored in the *OH* column, is when *fli* doesn't exist.\n",
    "\n",
    "For any potential conflict the user is referred to the additional information stored within the *verbose* column to accurately determine the serotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class EcoliResults:\n",
    "    \"\"\"\n",
    "    Object for holding and processing E. coli typing results.\n",
    "\n",
    "    This class stores summary typing data for multiple samples, provides utilities for per-sample processing, and export results in a tab-seperated format (.tsv).\n",
    "    \"\"\"\n",
    "\n",
    "    # converts the sample results in dict to pandas df\n",
    "    def __init__(self, results_dict: dict):\n",
    "        \"\"\"\n",
    "        Initializes the EcoliResults object with typing result data.\n",
    "\n",
    "        Args:\n",
    "            results_dict (dict): Dictionary where keys are sample names and values are summary result dictionaries.\n",
    "        \"\"\"\n",
    "        self.results_dict = results_dict\n",
    "        self.results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\").reset_index(names=\"sample_name\")\n",
    "\n",
    "    @staticmethod\n",
    "    def summarize_single_sample(sample_name: str, res_path: str, verbose_flag: int = 1) -> dict:\n",
    "        \"\"\"\n",
    "        Processes a single sample KMA .res file and returns a summary dictionary.\n",
    "\n",
    "        Args:\n",
    "            sample_name (str): Sample identifier.\n",
    "            res_path (str): Path to the sample's .res file.\n",
    "            verbose_flag (int, optional): Include verbose info if set to 1. Default is 1.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: Summary values extracted from the .res file.\n",
    "        \"\"\"\n",
    "        log_dir = \"examples/Log\"\n",
    "        setup_logging(log_dir, sample_name)\n",
    "\n",
    "        NA_string = \"-\"\n",
    "        output_data = {\n",
    "            \"stx\": NA_string,\n",
    "            \"OH\": NA_string, \"wzx\": NA_string, \"wzy\": NA_string, \"wzt\": NA_string, \"wzm\": NA_string,\n",
    "            \"eae\": NA_string, \"ehxA\": NA_string,\n",
    "            \"Other\": NA_string\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            logging.info(f\"Processing .res file: {res_path}\")\n",
    "            filtered_df = process_res_file(res_path)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to process {res_path}: {e}\")\n",
    "            return output_data\n",
    "\n",
    "        gene_map = {\n",
    "            \"wzx\": \"wzx\", \"wzy\": \"wzy\", \"wzt\": \"wzt\", \"wzm\": \"wzm\",\n",
    "            \"eae\": \"eae\", \"ehxA\": \"ehxA\"\n",
    "        }\n",
    "        toxin = \"stx\"\n",
    "        stx_alleles = set()\n",
    "        fli = NA_string\n",
    "        fliC = NA_string\n",
    "\n",
    "        for template in filtered_df[\"#Template\"]:\n",
    "            parts = template.split(\"__\")\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            gene, allele = parts[1], parts[2]\n",
    "\n",
    "            if gene in [\"eae\", \"ehxA\"]:\n",
    "                output_data[gene] = \"Positive\"\n",
    "            elif gene in gene_map:\n",
    "                output_data[gene] = allele\n",
    "            elif gene == \"fliC\":\n",
    "                fliC = allele\n",
    "            elif gene == \"fli\":\n",
    "                fli = allele\n",
    "            elif gene.startswith(toxin):\n",
    "                stx_alleles.add(allele)\n",
    "            elif gene not in thresholds:\n",
    "                output_data[\"Other\"] = allele\n",
    "\n",
    "        if stx_alleles:\n",
    "            output_data[toxin] = \";\".join(sorted(stx_alleles))\n",
    "\n",
    "        # serotype specific requirements\n",
    "        wzx, wzy, wzt, wzm = output_data[\"wzx\"], output_data[\"wzy\"], output_data[\"wzt\"], output_data[\"wzm\"]\n",
    "        Otype = \"-\"\n",
    "        if wzx != NA_string and wzy != NA_string and wzx == wzy and wzt == NA_string and wzm == NA_string:\n",
    "            Otype = wzx\n",
    "            output_data[\"wzx\"] = output_data[\"wzy\"] = NA_string\n",
    "        elif wzt != NA_string and wzm != NA_string and wzt == wzm and wzx == NA_string and wzy == NA_string:\n",
    "            Otype = wzt\n",
    "            output_data[\"wzt\"] = output_data[\"wzm\"] = NA_string\n",
    "\n",
    "        Htype = fli if fli != NA_string else fliC\n",
    "        output_data[\"OH\"] = f\"{Otype};{Htype}\"\n",
    "\n",
    "        # adding the additional depth, template coverage and query identity information\n",
    "        if verbose_flag == 1:\n",
    "            verbose_parts = []\n",
    "            for _, row in filtered_df.iterrows():\n",
    "                parts = row[\"#Template\"].split(\"__\")\n",
    "                if len(parts) >= 3:\n",
    "                    gene, allele = parts[1], parts[2]\n",
    "                    depth = row[\"Depth\"]\n",
    "                    coverage = row[\"Template_Coverage\"]\n",
    "                    identity = row[\"Query_Identity\"]\n",
    "                    verbose_parts.append(f\"{gene}_{allele}_{depth:.2f}_{coverage:.2f}_{identity:.2f}\")\n",
    "            output_data[\"verbose\"] = \";\".join(verbose_parts)\n",
    "\n",
    "        logging.info(f\"Successfully processed sample: {sample_name}\")\n",
    "        return output_data\n",
    "\n",
    "    @classmethod\n",
    "    def from_samplesheet(cls, \n",
    "                        samplesheet_path: Path, \n",
    "                        verbose: int = 1, \n",
    "                        results_base: str = \"examples/Results/{sample_name}/kma/{sample_name}.res\",\n",
    "                    ) -> \"EcoliResults\":\n",
    "        \"\"\"\n",
    "        Loads sample data from a samplesheet and summarizes each sample.\n",
    "\n",
    "        Args:\n",
    "            samplesheet_path (Path): Path to the samplesheet TSV file.\n",
    "            verbose (int, optional): Whether to include verbose output per sample. Default is 1.\n",
    "\n",
    "        Returns:\n",
    "            EcoliResults: An instance of the class populated with summaries for all samples.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(samplesheet_path, sep=\"\\t\")\n",
    "        df.columns = df.columns.str.strip()\n",
    "        #print(\"I AM INSIDE FROM SAMPLESHEET\")\n",
    "        #if \"Illumina_read_files\" in df.columns and (\"read1\" not in df.columns or \"read2\" not in df.columns):\n",
    "        #    df[[\"read1\", \"read2\"]] = df[\"Illumina_read_files\"].str.split(\",\", expand=True)\n",
    "\n",
    "        results_dict = {}\n",
    "        for idx, row in df.iterrows():\n",
    "            sample_name = row[\"sample_name\"]\n",
    "            res_path = Path(results_base.format(sample_name=sample_name)) #results_base / sample_name / \"kma\" / f\"{sample_name}.res\"\n",
    "            #print(f\"The res path is : {res_path}\")\n",
    "            summary = cls.summarize_single_sample(sample_name, res_path, verbose_flag=verbose)\n",
    "            results_dict[sample_name] = summary\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        result_df = pd.DataFrame.from_dict(results_dict, orient=\"index\").reset_index(names=\"sample_name\")\n",
    "\n",
    "        # Merge with original metadata\n",
    "        merged_df = df.merge(result_df, on=\"sample_name\", how=\"left\")\n",
    "\n",
    "        # Create and return object\n",
    "        obj = cls(results_dict)\n",
    "        obj.results_df = merged_df\n",
    "        return obj\n",
    "\n",
    "    def write_tsv(self, output_file: Path):\n",
    "        \"\"\"\n",
    "        Writes the summarized typing results to a TSV file.\n",
    "\n",
    "        Args:\n",
    "            output_file (Path): Destination file path for the output table.\n",
    "        \"\"\"\n",
    "        self.results_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Returns a concise summary of the results object.\n",
    "\n",
    "        Returns:\n",
    "            str: A string with sample and variable counts.\n",
    "        \"\"\"\n",
    "        return f\"<EcoliResults: {len(self.results_df)} samples, {len(self.results_df.columns)} variables>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser\n",
    "\n",
    "Defines the parser of the samplesheet to utilize the previously defined and described functionality to summarizes E. coli typing results for each sample.\n",
    "Outputs a TSV file or prints the results as a DataFrame, optionally with verbose detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def ecoli_parser(\n",
    "    samplesheet_path: Path,  # Input samplesheet\n",
    "    output_file: Path = None,  # Path to output\n",
    "    verbose: int = 1,  # Verbosity,\n",
    "    results_base: str = \"examples/Results/{sample_name}/kma/{sample_name}.res\"  # Path template for .res files\n",
    "):\n",
    "    results = EcoliResults.from_samplesheet(samplesheet_path, verbose=verbose, results_base=results_base)\n",
    "    if output_file:\n",
    "        results.write_tsv(output_file)\n",
    "    else:\n",
    "        print(results.results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING - empirical dataset\n",
    "\n",
    "Perform inline testing on two empirical datasets that verifies the functionality of the EcoliResults pipeline and datawrangling depending on the input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_output/Ecoli/KMA_cases_parser.tsv\n",
      "Logging started for examples/Log/ERR3528110_kma_fbi.log\n",
      "Processing .res file: test_input/Ecoli/ERR3528110.res\n",
      "Successfully processed sample: ERR3528110\n",
      "Logging started for examples/Log/ERR14229029_kma_fbi.log\n",
      "Processing .res file: test_input/Ecoli/ERR14229029.res\n",
      "Successfully processed sample: ERR14229029\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: true\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "samplesheet_path = Path(\"test_input/Ecoli/samplesheet.tsv\")\n",
    "output_dir = Path(\"test_output/Ecoli\")\n",
    "\n",
    "# Create output directory\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_path = output_dir / \"KMA_cases_parser.tsv\"\n",
    "\n",
    "# Assert input exists\n",
    "assert samplesheet_path.exists(), f\"File does not exist: {samplesheet_path}\"\n",
    "print(output_path)\n",
    "\n",
    "# try the ecoli parser to see if the wrangling functionality works\n",
    "try:\n",
    "    ecoli_parser(\n",
    "        samplesheet_path=samplesheet_path,\n",
    "        output_file=output_path,\n",
    "        verbose=1,\n",
    "        results_base=\"test_input/Ecoli/{sample_name}.res\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    raise AssertionError(f\"Parser execution failed: {e}\")\n",
    "\n",
    "# compare the output with the expected results based on input to ensure correct wrangling\n",
    "\n",
    "# read the created output files and check the information\n",
    "sample_sheet_df = pd.read_csv(samplesheet_path, sep=\"\\t\")\n",
    "sample_output_df = pd.read_csv(output_path, sep=\"\\t\")\n",
    "\n",
    "### Test case 1. Check if the datastructure is correct\n",
    "original_cols = sample_sheet_df.columns.tolist()\n",
    "output_cols = sample_output_df.columns.tolist()\n",
    "output_initial_cols = sample_output_df.columns[:len(original_cols)].tolist()\n",
    "output_specific_cols = sample_output_df.columns[len(original_cols):].tolist()\n",
    "\n",
    "assert original_cols == output_initial_cols, (\n",
    "    f\"Mismatch in first columns:\\nExpected: {original_cols}\\nGot: {output_initial_cols}\"\n",
    ")\n",
    "\n",
    "assert output_specific_cols\n",
    "\n",
    "### Test case 2. Check sample ERR3528110 which is correctly believed to be e.coli and ensure datawrangling does as expected\n",
    "ERR3528110_res_path = \"test_input/Ecoli/ERR3528110.res\"\n",
    "ERR3528110_input_df = pd.read_csv(ERR3528110_res_path, sep=\"\\t\")\n",
    "\n",
    "ERR3528110_row = sample_output_df[sample_output_df[\"sample_name\"] == \"ERR3528110\"].iloc[:,len(original_cols):len(output_cols)].iloc[0]\n",
    "\n",
    "#extract the original genes from the res\n",
    "gene_hits = ERR3528110_input_df[\"#Template\"].tolist()\n",
    "\n",
    "parsed_hits = []\n",
    "\n",
    "for hit in gene_hits:\n",
    "    parts = hit.split(\"__\")\n",
    "    assert len(parts) != 3, f\"Unexpected KMA result format in: '{hit}'. Expected at least 3 '__' parts (e.g., ref__gene__allele) as off ecoli fbi 24-04-2025.\"\n",
    "    gene, allele = parts[1], parts[2]\n",
    "    parsed_hits.append((gene, allele))\n",
    "\n",
    "# Extract OH genes \n",
    "O_gene_alleles = {gene: allele for gene, allele in parsed_hits if gene in {\"wzx\", \"wzy\", \"wzt\", \"wzm\"}}\n",
    "H_gene_alleles = {gene: allele for gene, allele in parsed_hits if gene in {\"fli\", \"fliC\"}}\n",
    "\n",
    "O_type = ERR3528110_row[\"OH\"].split(\";\")[0]\n",
    "H_type = ERR3528110_row[\"OH\"].split(\";\")[1]\n",
    "\n",
    "O_gene_keys = set(O_gene_alleles.keys())\n",
    "H_gene_keys = set(H_gene_alleles.keys())\n",
    "\n",
    "O_genes_no = len(O_gene_keys)\n",
    "H_genes_no = len(H_gene_keys)\n",
    "\n",
    "# O typing scenarios\n",
    "# Case 1: wzx/wzy match\n",
    "if O_gene_keys == {\"wzx\", \"wzy\"} and O_gene_alleles[\"wzx\"] == O_gene_alleles[\"wzy\"]:\n",
    "    expected_otype = O_gene_alleles[\"wzx\"]\n",
    "    assert O_type == expected_otype, f\"Expected OH '{expected_otype}', got '{O_type}'\"\n",
    "    # wzx/wzy should be suppressed\n",
    "    assert ERR3528110_row[\"wzx\"] == \"-\", \"wzx column should be '-' when OH is used\"\n",
    "    assert ERR3528110_row[\"wzy\"] == \"-\", \"wzy column should be '-' when OH is used\"\n",
    "    #print(f\"O-type correctly assigned from matching wzx/wzy: {O_type}\")\n",
    "\n",
    "# Case 2: wzt/wzm match\n",
    "elif O_gene_keys == {\"wzt\", \"wzm\"} and O_gene_alleles[\"wzt\"] == O_gene_alleles[\"wzm\"]:\n",
    "    expected_otype = O_gene_alleles[\"wzt\"]\n",
    "    assert O_type == expected_otype, f\"Expected OH '{expected_otype}', got '{O_type}'\"\n",
    "    assert ERR3528110_row[\"wzt\"] == \"-\", \"wzt column should be '-' when OH is used\"\n",
    "    assert ERR3528110_row[\"wzm\"] == \"-\", \"wzm column should be '-' when OH is used\"\n",
    "    #print(f\"O-type correctly assigned from matching wzt/wzm: {O_type}\")\n",
    "\n",
    "# Case 3: Conflict (≥3 genes, or 2 mismatched genes)\n",
    "elif O_genes_no >= 3 or (\n",
    "    (O_gene_keys == {\"wzx\", \"wzy\"} and O_gene_alleles[\"wzx\"] != O_gene_alleles[\"wzy\"]) or\n",
    "    (O_gene_keys == {\"wzt\", \"wzm\"} and O_gene_alleles[\"wzt\"] != O_gene_alleles[\"wzm\"])\n",
    "):\n",
    "    assert O_type == \"-\", f\"Expected OH = '-' due to conflict, got: '{O_type}'\"\n",
    "    for gene in O_gene_keys:\n",
    "        assert ERR3528110_row[gene] == O_gene_alleles[gene], f\"{gene} column should contain '{O_gene_alleles[gene]}'\"\n",
    "    #print(\"Conflict in O-typing correctly led to OH = '-' and individual gene columns retained.\")\n",
    "\n",
    "# H typing scenarios\n",
    "\n",
    "# Case 1: If fli is present it will always take precedence over fliC\n",
    "if H_gene_keys == {\"fli\"}:\n",
    "    expected_htype = H_gene_alleles[\"fli\"]\n",
    "    assert H_type == expected_htype, f\"Expected OH '{expected_htype}' from 'fli', got '{H_type}'\"\n",
    "\n",
    "# Case 2: only if fliC is the sole gene it is used\n",
    "elif H_gene_keys == {\"fliC\"}:\n",
    "    expected_htype = H_gene_alleles[\"fliC\"]\n",
    "    assert H_type == expected_htype, f\"Expected OH '{expected_htype}' from 'fliC', got '{H_type}'\"\n",
    "\n",
    "# Case 3: if none exist the H type remains empty\n",
    "else:\n",
    "    assert H_type == \"-\", f\"Expected H-type '-', but got '{H_type}'\"\n",
    "\n",
    "### Test case 3. Check sample ERR14229029 which is believed to be e.coli in the samplesheet is empty, as a result of being erroneously classified as e.coli\n",
    "\n",
    "ERR14229029_row = sample_output_df[sample_output_df[\"sample_name\"] == \"ERR14229029\"].iloc[:,len(original_cols):len(output_cols)].iloc[0]\n",
    "\n",
    "ERR14229029_expected_values = ['-', '-;-', '-', '-', '-', '-', '-', '-', '-', float('nan')]\n",
    "ERR14229029_values = [ERR14229029_row[col] for col in output_specific_cols]\n",
    "\n",
    "for col, actual, expected in zip(output_specific_cols, ERR14229029_values, ERR14229029_expected_values):\n",
    "    if pd.isna(expected):\n",
    "        assert pd.isna(actual), f\"{col}: Expected NaN, got {actual}\"\n",
    "    else:\n",
    "        assert actual == expected, f\"{col}: Expected '{expected}', got '{actual}'\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING - syntehtic data\n",
    "\n",
    "Defines several scenarions of 12 samples representing syntehtic *KMA .res* content to perform several case specific results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging started for examples/Log/sample1_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample1/kma/sample1.res\n",
      "Successfully processed sample: sample1\n",
      "Logging started for examples/Log/sample2_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample2/kma/sample2.res\n",
      "Successfully processed sample: sample2\n",
      "Logging started for examples/Log/sample3_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample3/kma/sample3.res\n",
      "Successfully processed sample: sample3\n",
      "Logging started for examples/Log/sample4_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample4/kma/sample4.res\n",
      "Successfully processed sample: sample4\n",
      "Logging started for examples/Log/sample5_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample5/kma/sample5.res\n",
      "Successfully processed sample: sample5\n",
      "Logging started for examples/Log/sample6_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample6/kma/sample6.res\n",
      "Successfully processed sample: sample6\n",
      "Logging started for examples/Log/sample7_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample7/kma/sample7.res\n",
      "Successfully processed sample: sample7\n",
      "Logging started for examples/Log/sample8_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample8/kma/sample8.res\n",
      "Successfully processed sample: sample8\n",
      "Logging started for examples/Log/sample9_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample9/kma/sample9.res\n",
      "Successfully processed sample: sample9\n",
      "Logging started for examples/Log/sample10_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample10/kma/sample10.res\n",
      "Successfully processed sample: sample10\n",
      "Logging started for examples/Log/sample11_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample11/kma/sample11.res\n",
      "Successfully processed sample: sample11\n",
      "Logging started for examples/Log/sample12_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample12/kma/sample12.res\n",
      "Successfully processed sample: sample12\n",
      "All 12 syntehtic E. coli sample inline tests passed.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "\n",
    "test_cases = [\n",
    "    # sample_name, res_content, expected_oh, expected_stx, expected_eae, expected_ehxA\n",
    "    (\"sample1\", \"1__wzx__O103__X\\t100\\t100\\t60\\n2__wzy__O103__X\\t100\\t100\\t65\\n3__fliC__H2__X\\t100\\t100\\t70\", \"O103;H2\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample2\", \"1__wzt__O8__X\\t100\\t100\\t60\\n2__wzm__O8__X\\t100\\t100\\t65\\n3__fliC__H10__X\\t100\\t100\\t70\\n4__stx2__stx2-a__X\\t100\\t100\\t90\\n5__eae__eae-5__X\\t100\\t100\\t80\", \"O8;H10\", \"stx2-a\", \"Positive\", \"-\"),\n",
    "    (\"sample3\", \"1__fliC__H7__X\\t100\\t100\\t70\", \"-;H7\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample4\", \"bad_line\\n2__wzy__O111__X\\t100\\t100\\t70\\n3__fliC__H11__X\\t100\\t100\\t70\", \"-;H11\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample5\", \"\", \"-;-\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample6\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O157__X\\t100\\t100\\t65\\n3__wzt__O8__X\\t100\\t100\\t60\\n4__wzm__O8__X\\t100\\t100\\t65\\n5__fli__H2__X\\t100\\t100\\t70\", \"-;H2\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample7\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O111__X\\t100\\t100\\t65\\n3__fliC__H9__X\\t100\\t100\\t70\", \"-;H9\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample8\", \"1__fli__H1__X\\t100\\t100\\t70\\n2__fliC__H12__X\\t100\\t100\\t70\", \"-;H1\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample9\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O157__X\\t100\\t100\\t65\\n3__wzt__O8__X\\t100\\t100\\t60\\n4__wzm__O8__X\\t100\\t100\\t65\\n5__fliC__H10__X\\t100\\t100\\t70\\n6__fli__H2__X\\t100\\t100\\t70\\n7__stx1__stx1-a__X\\t100\\t100\\t90\\n8__stx2__stx2-d__X\\t100\\t100\\t90\\n9__stx2__stx2-a__X\\t100\\t100\\t90\\n10__eae__eae-42-5__X\\t100\\t100\\t80\\n11__ehxA__ehxA-7__X\\t100\\t100\\t80\", \"-;H2\", \"stx1-a;stx2-a;stx2-d\", \"Positive\", \"Positive\"),\n",
    "    (\"sample10\", \"1__adk__adk__X\\t100\\t100\\t70\\n2__fliC__H4__X\\t100\\t100\\t70\", \"-;H4\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample11\", \"1__eae__eae-1__X\\t100\\t94\\t70\\n2__fliC__H6__X\\t100\\t100\\t70\", \"-;H6\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample12\", \"1__stx1__stx1a__X\\t100\\t100\\t80\\n2__stx2__stx2c__X\\t100\\t100\\t85\\n3__fli__H21__X\\t100\\t100\\t70\", \"-;H21\", \"stx1a;stx2c\", \"-\", \"-\"),\n",
    "]\n",
    "\n",
    "for sample_name, res_content, expected_oh, expected_stx, expected_eae, expected_ehxA in test_cases:\n",
    "    with TemporaryDirectory() as tmpdir:\n",
    "        tmpdir = Path(tmpdir)\n",
    "        os.chdir(tmpdir)\n",
    "\n",
    "        res_dir = tmpdir / f\"examples/Results/{sample_name}/kma\"\n",
    "        res_dir.mkdir(parents=True)\n",
    "        res_file = res_dir / f\"{sample_name}.res\"\n",
    "        res_file.write_text(\"#Template\\tTemplate_Coverage\\tQuery_Identity\\tDepth\\n\" + res_content)\n",
    "\n",
    "        sheet = tmpdir / \"samplesheet.tsv\"\n",
    "        sheet.write_text(\n",
    "            \"sample_name\\tIllumina_read_files\\tNanopore_read_file\\tassembly_file\\torganism\\tvariant\\tnotes\\n\"\n",
    "            f\"{sample_name}\\tread1.fastq,read2.fastq\\t-\\t-\\tEcoli\\t-\\t-\\n\"\n",
    "        )\n",
    "\n",
    "        results = EcoliResults.from_samplesheet(sheet)\n",
    "        df = results.results_df\n",
    "        row = df.iloc[0]\n",
    "        \n",
    "        # general output and functionality test\n",
    "        assert row[\"sample_name\"] == sample_name\n",
    "        \n",
    "        if row[\"OH\"] != expected_oh:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected OH: {expected_oh}\\nActual OH: {row['OH']}\")\n",
    "        assert row[\"OH\"] == expected_oh\n",
    "        \n",
    "        if row[\"stx\"] != expected_stx:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected stx: {expected_stx}\\nActual stx: {row['stx']}\")\n",
    "        assert row[\"stx\"] == expected_stx\n",
    "\n",
    "        if row[\"eae\"] != expected_eae:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected eae: {expected_eae}\\nActual eae: {row['eae']}\")\n",
    "        assert row[\"eae\"] == expected_eae\n",
    "\n",
    "        if row[\"ehxA\"] != expected_ehxA:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected ehxA: {expected_ehxA}\\nActual ehxA: {row['ehxA']}\")\n",
    "        assert row[\"ehxA\"] == expected_ehxA\n",
    "\n",
    "        # sample specific information tests\n",
    "        \n",
    "        # without confliciting O and H typing, the OH column should be filled and the remaining four genes empty\n",
    "        if sample_name == \"sample1\": \n",
    "            assert row[\"wzx\"] == \"-\"\n",
    "            assert row[\"wzy\"] == \"-\"\n",
    "            assert row[\"wzt\"] == \"-\"\n",
    "            assert row[\"wzm\"] == \"-\"\n",
    "        # with conflicts the OH should remain empty and the four 'conflicting' gene information remain filled\n",
    "        elif sample_name == \"sample6\":\n",
    "            assert row[\"wzx\"] == \"O157\"\n",
    "            assert row[\"wzy\"] == \"O157\"\n",
    "            assert row[\"wzt\"] == \"O8\"\n",
    "            assert row[\"wzm\"] == \"O8\"\n",
    "        elif sample_name == \"sample10\":\n",
    "            assert row[\"Other\"] == \"adk\"\n",
    "\n",
    "print(\"All 12 syntehtic E. coli sample inline tests passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directive for ensuring that the code in your notebook get executed as a script\n",
    "\n",
    "The code-block here below is required to ensure that the code in the notebook is also transferred to the module (script), otherwise it will just be a notebook. See [Coding in NBdev](https://dksund.sharepoint.com/:fl:/g/contentstorage/CSP_7c761ee7-b577-4e08-8517-bc82392bf65e/ETlSfUyArSNJhX8veMI_JQ8By1aXGHzDJkhotpfpXx4mmw?e=037EwH&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF83Yzc2MWVlNy1iNTc3LTRlMDgtODUxNy1iYzgyMzkyYmY2NWUmZD1iJTIxNXg1MmZIZTFDRTZGRjd5Q09TdjJYblkwVlNiWXFYcE1yaHVrVmZqTVJUVEE4X1VwZjhTd1JxcjRNdmFrSmh2RCZmPTAxVlVLVzVWSlpLSjZVWkFGTkVORVlLN1pQUERCRDZKSVAmYz0lMkYmYT1Mb29wQXBwJnA9JTQwZmx1aWR4JTJGbG9vcC1wYWdlLWNvbnRhaW5lciZ4PSU3QiUyMnclMjIlM0ElMjJUMFJUVUh4a2EzTjFibVF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUUxZURVeVpraGxNVU5GTmtaR04zbERUMU4yTWxodVdUQldVMkpaY1Zod1RYSm9kV3RXWm1wTlVsUlVRVGhmVlhCbU9GTjNVbkZ5TkUxMllXdEthSFpFZkRBeFZsVkxWelZXU1RJMVJsaFBNalkyUlZkQ1FqTTFRVmhKVTBkRFVVcFdXa1klM0QlMjIlMkMlMjJpJTIyJTNBJTIyNzRmNzM1ZmUtYzg4Ny00MjhhLWFkZmYtNTEyZTg2YmNmZmQzJTIyJTdE) \n",
    "(**Writing your own notebooks**) on loop for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nbdev'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# | hide\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This is included at the end to ensure when you run through your notebook the code is also transferred to the module and isn't just a notebook\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnbdev\u001b[39;00m\n\u001b[32m      5\u001b[39m nbdev.nbdev_export()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nbdev'"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# This is included at the end to ensure when you run through your notebook the code is also transferred to the module and isn't just a notebook\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FBI_RAAH_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
