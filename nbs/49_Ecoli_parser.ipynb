{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directive for creating a script for your notebook\n",
    "\n",
    "The block here below is required at the top of each notebook that you want to create a script for. You will also need to edit the \"settings.ini\" file, to create a script (see [Coding in NBdev](https://dksund.sharepoint.com/:fl:/g/contentstorage/CSP_7c761ee7-b577-4e08-8517-bc82392bf65e/ETlSfUyArSNJhX8veMI_JQ8By1aXGHzDJkhotpfpXx4mmw?e=037EwH&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF83Yzc2MWVlNy1iNTc3LTRlMDgtODUxNy1iYzgyMzkyYmY2NWUmZD1iJTIxNXg1MmZIZTFDRTZGRjd5Q09TdjJYblkwVlNiWXFYcE1yaHVrVmZqTVJUVEE4X1VwZjhTd1JxcjRNdmFrSmh2RCZmPTAxVlVLVzVWSlpLSjZVWkFGTkVORVlLN1pQUERCRDZKSVAmYz0lMkYmYT1Mb29wQXBwJnA9JTQwZmx1aWR4JTJGbG9vcC1wYWdlLWNvbnRhaW5lciZ4PSU3QiUyMnclMjIlM0ElMjJUMFJUVUh4a2EzTjFibVF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUUxZURVeVpraGxNVU5GTmtaR04zbERUMU4yTWxodVdUQldVMkpaY1Zod1RYSm9kV3RXWm1wTlVsUlVRVGhmVlhCbU9GTjNVbkZ5TkUxMllXdEthSFpFZkRBeFZsVkxWelZXU1RJMVJsaFBNalkyUlZkQ1FqTTFRVmhKVTBkRFVVcFdXa1klM0QlMjIlMkMlMjJpJTIyJTNBJTIyNzRmNzM1ZmUtYzg4Ny00MjhhLWFkZmYtNTEyZTg2YmNmZmQzJTIyJTdE) \n",
    "(**Writing your own notebooks**) on loop for more details). Replace **some_string** with a name that makes sense for your notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Ecoli_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "Include all the libraries which should be used in this *Escherichia coli* module, to create log the various operations to load input files, craete datastructures, maniplate and output desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime \n",
    "from typing import List, Dict \n",
    "from fastcore.script import call_parse\n",
    "#import functions from core module (optional, but most likely needed). \n",
    "from ssi_analysis_result_parsers import(\n",
    "    core\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\n",
    "os.chdir(core.PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Necessary functins to extract *k-mer alignment (KMA tool)* results from *.res* files to perform following steps\n",
    "\n",
    "- Extract data \n",
    "- Filter data based on gene-specific thresholds for the *template coverage* and *Query identity*\n",
    "- Perform *OH* typing and *stx* detection based on gene-specific information\n",
    "- Wrangle data using *pandas* dataframes creating accurate data structure\n",
    "- Store results in either sample-specific output files or one full tsv file extending the original samplesheet information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "thresholds = {\n",
    "    \"stx\": [98, 98],\n",
    "    \"wzx\": [98, 98],\n",
    "    \"wzy\": [98, 98],\n",
    "    \"wzt\": [98, 98],\n",
    "    \"wzm\": [98, 98],\n",
    "    \"fliC\": [90, 90],\n",
    "    \"fli\": [90, 90],\n",
    "    \"eae\": [95, 95],\n",
    "    \"ehxA\": [95, 95],\n",
    "    \"other\": [98, 98]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds\n",
    "\n",
    "Defines gene-specific tresholds used to filter the input *KMA .res* files on the columns [*template coverage*,*Query identity*] to identify genes related to:\n",
    "- Shiga Toxin (stx1 and stx2 subtypes)\n",
    "- Serotyping using O-antigens with Serotype genes (wzx,wzy,wzt,wzm) and H-antigen using Flagellar genes (fli & fliC)\n",
    "- Surface adhesion for EPEC and STEC strains with eae gene \n",
    "- Hemolytic toxin (ehxA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging\n",
    "\n",
    "Defines a logging setup function used throughout the later functions to record information and errors both to a per-sample log file. \n",
    "\n",
    "The log file is created inside the specified log directory with a filename based on the sample name. The log file contains detailed messages with information of the progression, errors and warnings with timestamps. Which is useful for tracing execution and diagnosing issues per sample in multi-sample pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def setup_logging(log_dir: str, sample_name: str) -> None:\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file = os.path.join(log_dir, f\"{sample_name}_kma_fbi.log\")\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    while logger.hasHandlers():\n",
    "        logger.removeHandler(logger.handlers[0])\n",
    "\n",
    "    logging.basicConfig(\n",
    "        filename=log_file,\n",
    "        filemode=\"a\",\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        level=logging.INFO\n",
    "    )\n",
    "\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    logging.info(f\"Logging started for {log_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds filtering & .res parsing\n",
    "\n",
    "For each gene specified earlier, the thresholds for the template coverage and query identity is extracted and used to filter the input *KMA .res* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_threshold(template_name: str, thresholds: Dict[str, List[int]]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Returns the coverage and identity threshold for a given gene.\n",
    "\n",
    "    Args:\n",
    "        template_name (str): Name of the template (gene) from the .res file.\n",
    "        thresholds (Dict[str, List[int]]): Dictionary of gene thresholds.\n",
    "\n",
    "    Returns:\n",
    "        List[int]: A list of two integers: [coverage_threshold, identity_threshold].\n",
    "    \"\"\"\n",
    "    for key in thresholds:\n",
    "        if key in template_name:\n",
    "            return thresholds[key]\n",
    "    return thresholds[\"other\"]\n",
    "\n",
    "def process_res_file(res_file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads and filters a KMA .res file based on predefined thresholds.\n",
    "\n",
    "    Args:\n",
    "        res_file_path (str): Path to the .res file.\n",
    "        thresholds (Dict[str, List[int]]): Gene-specific thresholds.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered results DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        res_df = pd.read_csv(res_file_path, sep=\"\\t\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File not found: {res_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(f\"File is empty or not properly formatted: {res_file_path}\")\n",
    "\n",
    "    required_columns = {\"#Template\", \"Template_Coverage\", \"Query_Identity\", \"Depth\"}\n",
    "    if not required_columns.issubset(res_df.columns):\n",
    "        raise ValueError(f\"Missing expected columns in {res_file_path}\")\n",
    "\n",
    "    res_df[\"threshold\"] = res_df[\"#Template\"].apply(lambda x: get_threshold(x, thresholds))\n",
    "    res_df_filtered = res_df[\n",
    "        (res_df[\"Template_Coverage\"] >= res_df[\"threshold\"].apply(lambda x: x[0])) &\n",
    "        (res_df[\"Query_Identity\"] >= res_df[\"threshold\"].apply(lambda x: x[1]))\n",
    "    ]\n",
    "    return res_df_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escherichia coli results\n",
    "\n",
    "Defines a class to parse, summarize and export the *E. coli* gene typing results from the filtered .res input files. \n",
    "It creates per-sample logging and outputs the results either pr sample in their respective directories with all input files or as one conjoined file extending the input samplesheet file. The class allows for an additional column in the final output with a more detailed and summarize gene-specific information of the Depth,template coverage, query identity.\n",
    "\n",
    "With the final output with verbose option having the following structure\n",
    "\n",
    "| sample_name | illumina_read_files | nanopore_read_file | assembly_file | organism | variant | notes | stx | OH | wzx | wzy | wzt | wzm | eae | ehxA | Other | verbose|\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "\n",
    "The Serotyping results in the above structure has gene-specific requirements.\n",
    "\n",
    "- If *wzx* and *wzy* are the sole O-antigen genes with no conflicts between them, that information is used as the O-type result and stored in the *OH* column, otherwise the results are store in the *wzx* and *wzy* columns and O-type in the *OH* column remains empty \n",
    "- If *wzt* and *wzm* are the sole O-antigen genes with no conflicts between them, that information is used as the O-type result and stored in the *OH* column, otherwise the results are store in the *wzt* and *wzm* columns and O-type in the *OH* column remains empty  \n",
    "- If all O-antigen genes exist in the *KMA* results, the O-type in the *OH* column remains empty and all four *wzx,wzy,wzt,wzm* columns are filled\n",
    "- If *fli* exist in the *KMA* results that information is used as the H-type and stored in the *OH* column. The only scenario where *fliC* is used to determine the H-type and stored in the *OH* column, is when *fli* doesn't exist.\n",
    "\n",
    "For any potential conflict the user is referred to the additional information stored within the *verbose* column to accurately determine the serotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class EcoliResults:\n",
    "    \"\"\"\n",
    "    Object for holding and processing E. coli typing results.\n",
    "\n",
    "    This class stores summary typing data for multiple samples, provides utilities for per-sample processing, and export results in a tab-seperated format (.tsv).\n",
    "    \"\"\"\n",
    "\n",
    "    # converts the sample results in dict to pandas df\n",
    "    def __init__(self, results_dict: dict):\n",
    "        \"\"\"\n",
    "        Initializes the EcoliResults object with typing result data.\n",
    "\n",
    "        Args:\n",
    "            results_dict (dict): Dictionary where keys are sample names and values are summary result dictionaries.\n",
    "        \"\"\"\n",
    "        self.results_dict = results_dict\n",
    "        self.results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\").reset_index(names=\"sample_name\")\n",
    "\n",
    "    @staticmethod\n",
    "    def summarize_single_sample(sample_name: str, res_path: str, verbose_flag: int = 1) -> dict:\n",
    "        \"\"\"\n",
    "        Processes a single sample KMA .res file and returns a summary dictionary.\n",
    "\n",
    "        Args:\n",
    "            sample_name (str): Sample identifier.\n",
    "            res_path (str): Path to the sample's .res file.\n",
    "            verbose_flag (int, optional): Include verbose info if set to 1. Default is 1.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: Summary values extracted from the .res file.\n",
    "        \"\"\"\n",
    "        log_dir = \"examples/Log\"\n",
    "        setup_logging(log_dir, sample_name)\n",
    "\n",
    "        NA_string = \"-\"\n",
    "        output_data = {\n",
    "            \"stx\": NA_string,\n",
    "            \"OH\": NA_string, \"wzx\": NA_string, \"wzy\": NA_string, \"wzt\": NA_string, \"wzm\": NA_string,\n",
    "            \"eae\": NA_string, \"ehxA\": NA_string,\n",
    "            \"Other\": NA_string\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            logging.info(f\"Processing .res file: {res_path}\")\n",
    "            filtered_df = process_res_file(res_path)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to process {res_path}: {e}\")\n",
    "            return output_data\n",
    "\n",
    "        gene_map = {\n",
    "            \"wzx\": \"wzx\", \"wzy\": \"wzy\", \"wzt\": \"wzt\", \"wzm\": \"wzm\",\n",
    "            \"eae\": \"eae\", \"ehxA\": \"ehxA\"\n",
    "        }\n",
    "        toxin = \"stx\"\n",
    "        stx_alleles = set()\n",
    "        fli = NA_string\n",
    "        fliC = NA_string\n",
    "\n",
    "        for template in filtered_df[\"#Template\"]:\n",
    "            parts = template.split(\"__\")\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            gene, allele = parts[1], parts[2]\n",
    "\n",
    "            if gene in [\"eae\", \"ehxA\"]:\n",
    "                output_data[gene] = \"Positive\"\n",
    "            elif gene in gene_map:\n",
    "                output_data[gene] = allele\n",
    "            elif gene == \"fliC\":\n",
    "                fliC = allele\n",
    "            elif gene == \"fli\":\n",
    "                fli = allele\n",
    "            elif gene.startswith(toxin):\n",
    "                stx_alleles.add(allele)\n",
    "            elif gene not in thresholds:\n",
    "                output_data[\"Other\"] = allele\n",
    "\n",
    "        if stx_alleles:\n",
    "            output_data[toxin] = \";\".join(sorted(stx_alleles))\n",
    "\n",
    "        # serotype specific requirements\n",
    "        wzx, wzy, wzt, wzm = output_data[\"wzx\"], output_data[\"wzy\"], output_data[\"wzt\"], output_data[\"wzm\"]\n",
    "        Otype = \"-\"\n",
    "        if wzx != NA_string and wzy != NA_string and wzx == wzy and wzt == NA_string and wzm == NA_string:\n",
    "            Otype = wzx\n",
    "            output_data[\"wzx\"] = output_data[\"wzy\"] = NA_string\n",
    "        elif wzt != NA_string and wzm != NA_string and wzt == wzm and wzx == NA_string and wzy == NA_string:\n",
    "            Otype = wzt\n",
    "            output_data[\"wzt\"] = output_data[\"wzm\"] = NA_string\n",
    "\n",
    "        Htype = fli if fli != NA_string else fliC\n",
    "        output_data[\"OH\"] = f\"{Otype};{Htype}\"\n",
    "\n",
    "        # adding the additional depth, template coverage and query identity information\n",
    "        if verbose_flag == 1:\n",
    "            verbose_parts = []\n",
    "            for _, row in filtered_df.iterrows():\n",
    "                parts = row[\"#Template\"].split(\"__\")\n",
    "                if len(parts) >= 3:\n",
    "                    gene, allele = parts[1], parts[2]\n",
    "                    depth = row[\"Depth\"]\n",
    "                    coverage = row[\"Template_Coverage\"]\n",
    "                    identity = row[\"Query_Identity\"]\n",
    "                    verbose_parts.append(f\"{gene}_{allele}_{depth:.2f}_{coverage:.2f}_{identity:.2f}\")\n",
    "            output_data[\"verbose\"] = \";\".join(verbose_parts)\n",
    "\n",
    "        logging.info(f\"Successfully processed sample: {sample_name}\")\n",
    "        return output_data\n",
    "\n",
    "    @classmethod\n",
    "    def from_samplesheet(cls, \n",
    "                        samplesheet_path: Path, \n",
    "                        verbose: int = 1, \n",
    "                        results_base: str = \"examples/Results/{sample_name}/kma/{sample_name}.res\",\n",
    "                    ) -> \"EcoliResults\":\n",
    "        \"\"\"\n",
    "        Loads sample data from a samplesheet and summarizes each sample.\n",
    "\n",
    "        Args:\n",
    "            samplesheet_path (Path): Path to the samplesheet TSV file.\n",
    "            verbose (int, optional): Whether to include verbose output per sample. Default is 1.\n",
    "\n",
    "        Returns:\n",
    "            EcoliResults: An instance of the class populated with summaries for all samples.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(samplesheet_path, sep=\"\\t\")\n",
    "        df.columns = df.columns.str.strip()\n",
    "        print(\"I AM INSIDE FROM SAMPLESHEET\")\n",
    "        if \"Illumina_read_files\" in df.columns and (\"read1\" not in df.columns or \"read2\" not in df.columns):\n",
    "            df[[\"read1\", \"read2\"]] = df[\"Illumina_read_files\"].str.split(\",\", expand=True)\n",
    "\n",
    "        results_dict = {}\n",
    "        for idx, row in df.iterrows():\n",
    "            sample_name = row[\"sample_name\"]\n",
    "            res_path = Path(results_base.format(sample_name=sample_name)) #results_base / sample_name / \"kma\" / f\"{sample_name}.res\"\n",
    "            print(f\"The res path is : {res_path}\")\n",
    "            summary = cls.summarize_single_sample(sample_name, res_path, verbose_flag=verbose)\n",
    "            results_dict[sample_name] = summary\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        result_df = pd.DataFrame.from_dict(results_dict, orient=\"index\").reset_index(names=\"sample_name\")\n",
    "\n",
    "        # Merge with original metadata\n",
    "        merged_df = df.merge(result_df, on=\"sample_name\", how=\"left\")\n",
    "\n",
    "        # Create and return object\n",
    "        obj = cls(results_dict)\n",
    "        obj.results_df = merged_df\n",
    "        return obj\n",
    "\n",
    "    def write_tsv(self, output_file: Path):\n",
    "        \"\"\"\n",
    "        Writes the summarized typing results to a TSV file.\n",
    "\n",
    "        Args:\n",
    "            output_file (Path): Destination file path for the output table.\n",
    "        \"\"\"\n",
    "        self.results_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Returns a concise summary of the results object.\n",
    "\n",
    "        Returns:\n",
    "            str: A string with sample and variable counts.\n",
    "        \"\"\"\n",
    "        return f\"<EcoliResults: {len(self.results_df)} samples, {len(self.results_df.columns)} variables>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser\n",
    "\n",
    "Defines the parser of the samplesheet to utilize the previously defined and described functionality to summarizes E. coli typing results for each sample.\n",
    "Outputs a TSV file or prints the results as a DataFrame, optionally with verbose detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def ecoli_parser(\n",
    "    samplesheet_path: Path,  # Input samplesheet\n",
    "    output_file: Path = None,  # Path to output\n",
    "    verbose: int = 1,  # Verbosity,\n",
    "    results_base: str = \"examples/Results/{sample_name}/kma/{sample_name}.res\"  # Path template for .res files\n",
    "):\n",
    "    results = EcoliResults.from_samplesheet(samplesheet_path, verbose=verbose, results_base=results_base)\n",
    "    if output_file:\n",
    "        results.write_tsv(output_file)\n",
    "    else:\n",
    "        print(results.results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING\n",
    "\n",
    "Defines several scenarions of 12 samples representing syntehtic *KMA .res* content and two empirical datasets to perform inline testing that verifies the functionality of the EcoliResults pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /dpssi/home/henras/Ecoli/ssi_analysis_result_parsers\n",
      "Samplesheet exists: True\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : test_input/Ecoli/ERR3528110.res\n",
      "Logging started for examples/Log/ERR3528110_kma_fbi.log\n",
      "Processing .res file: test_input/Ecoli/ERR3528110.res\n",
      "Successfully processed sample: ERR3528110\n",
      "The res path is : test_input/Ecoli/ERR14229029.res\n",
      "Logging started for examples/Log/ERR14229029_kma_fbi.log\n",
      "Processing .res file: test_input/Ecoli/ERR14229029.res\n",
      "Successfully processed sample: ERR14229029\n",
      "Output path: True\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: true\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "samplesheet_path = Path(\"test_input/Ecoli/samplesheet.tsv\")\n",
    "output_path = Path(\"test_output/Ecoli/KMA_cases_parser.tsv\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Samplesheet exists:\", samplesheet_path.exists())\n",
    "\n",
    "try:\n",
    "    ecoli_parser(\n",
    "        samplesheet_path=samplesheet_path,\n",
    "        output_file=output_path,\n",
    "        verbose=1,\n",
    "        results_base=\"test_input/Ecoli/{sample_name}.res\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Error occurred:\", e)\n",
    "\n",
    "print(\"Output path:\", output_path.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THOR SUGGESTIONS\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : test_input/Ecoli/ERR3528110.res\n",
      "Logging started for examples/Log/ERR3528110_kma_fbi.log\n",
      "Processing .res file: test_input/Ecoli/ERR3528110.res\n",
      "Successfully processed sample: ERR3528110\n",
      "The res path is : test_input/Ecoli/ERR14229029.res\n",
      "Logging started for examples/Log/ERR14229029_kma_fbi.log\n",
      "Processing .res file: test_input/Ecoli/ERR14229029.res\n",
      "Successfully processed sample: ERR14229029\n",
      "<EcoliResults: 2 samples, 19 variables>\n",
      "test_output/Ecoli/KMA_cases.tsv\n",
      "   sample_name                                Illumina_read_files  \\\n",
      "0   ERR3528110  examples/Dataset/reads/ERR3528110_1.fastq.gz,e...   \n",
      "1  ERR14229029  examples/Dataset/reads/ERR14229029_1.fastq.gz,...   \n",
      "\n",
      "  Nanopore_read_file                                  assembly_file organism  \\\n",
      "0                 Na   examples/Dataset/assemblies/ERR3528110.fasta   E.coli   \n",
      "1                 Na  examples/Dataset/assemblies/ERR14229029.fasta   E.coli   \n",
      "\n",
      "  variant notes                                          read1  \\\n",
      "0      Na    Na   examples/Dataset/reads/ERR3528110_1.fastq.gz   \n",
      "1      Na    Na  examples/Dataset/reads/ERR14229029_1.fastq.gz   \n",
      "\n",
      "                                           read2 stx     OH wzx wzy wzt wzm  \\\n",
      "0   examples/Dataset/reads/ERR3528110_2.fastq.gz   -  O6;H1   -   -   -   -   \n",
      "1  examples/Dataset/reads/ERR14229029_2.fastq.gz   -    -;-   -   -   -   -   \n",
      "\n",
      "  eae ehxA Other                                            verbose  \n",
      "0   -    -     -  wzx_O6_16.07_100.00_99.92;wzy_O6_17.35_100.00_...  \n",
      "1   -    -     -                                                     \n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: true\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"THOR SUGGESTIONS\")\n",
    "\n",
    "# Define input samplesheet and output path\n",
    "samplesheet_path = Path(\"test_input/Ecoli/samplesheet.tsv\")\n",
    "output_path = Path(\"test_output/Ecoli/KMA_cases.tsv\")\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate results using the from_samplesheet class method\n",
    "#results_obj = EcoliResults.from_samplesheet(samplesheet_path, verbose=1, results_base=Path(\"test_input/Ecoli\"))\n",
    "\n",
    "samplesheet_path = Path(\"test_input/Ecoli/samplesheet.tsv\")\n",
    "results_path_template = \"test_input/Ecoli/{sample_name}.res\"\n",
    "\n",
    "results_obj = EcoliResults.from_samplesheet(\n",
    "    samplesheet_path, \n",
    "    verbose=1, \n",
    "    results_base=results_path_template\n",
    ")\n",
    "print(results_obj)\n",
    "# Write to output TSV\n",
    "results_obj.write_tsv(output_path)\n",
    "print(output_path)\n",
    "# Print the dataframe\n",
    "print(results_obj.results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample1/kma/sample1.res\n",
      "Logging started for examples/Log/sample1_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample1/kma/sample1.res\n",
      "Successfully processed sample: sample1\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample2/kma/sample2.res\n",
      "Logging started for examples/Log/sample2_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample2/kma/sample2.res\n",
      "Successfully processed sample: sample2\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample3/kma/sample3.res\n",
      "Logging started for examples/Log/sample3_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample3/kma/sample3.res\n",
      "Successfully processed sample: sample3\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample4/kma/sample4.res\n",
      "Logging started for examples/Log/sample4_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample4/kma/sample4.res\n",
      "Successfully processed sample: sample4\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample5/kma/sample5.res\n",
      "Logging started for examples/Log/sample5_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample5/kma/sample5.res\n",
      "Successfully processed sample: sample5\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample6/kma/sample6.res\n",
      "Logging started for examples/Log/sample6_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample6/kma/sample6.res\n",
      "Successfully processed sample: sample6\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample7/kma/sample7.res\n",
      "Logging started for examples/Log/sample7_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample7/kma/sample7.res\n",
      "Successfully processed sample: sample7\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample8/kma/sample8.res\n",
      "Logging started for examples/Log/sample8_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample8/kma/sample8.res\n",
      "Successfully processed sample: sample8\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample9/kma/sample9.res\n",
      "Logging started for examples/Log/sample9_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample9/kma/sample9.res\n",
      "Successfully processed sample: sample9\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample10/kma/sample10.res\n",
      "Logging started for examples/Log/sample10_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample10/kma/sample10.res\n",
      "Successfully processed sample: sample10\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample11/kma/sample11.res\n",
      "Logging started for examples/Log/sample11_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample11/kma/sample11.res\n",
      "Successfully processed sample: sample11\n",
      "I AM INSIDE FROM SAMPLESHEET\n",
      "The res path is : examples/Results/sample12/kma/sample12.res\n",
      "Logging started for examples/Log/sample12_kma_fbi.log\n",
      "Processing .res file: examples/Results/sample12/kma/sample12.res\n",
      "Successfully processed sample: sample12\n",
      "All 12 syntehtic E. coli sample inline tests passed.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "\n",
    "test_cases = [\n",
    "    # sample_name, res_content, expected_oh, expected_stx, expected_eae, expected_ehxA\n",
    "    (\"sample1\", \"1__wzx__O103__X\\t100\\t100\\t60\\n2__wzy__O103__X\\t100\\t100\\t65\\n3__fliC__H2__X\\t100\\t100\\t70\", \"O103;H2\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample2\", \"1__wzt__O8__X\\t100\\t100\\t60\\n2__wzm__O8__X\\t100\\t100\\t65\\n3__fliC__H10__X\\t100\\t100\\t70\\n4__stx2__stx2-a__X\\t100\\t100\\t90\\n5__eae__eae-5__X\\t100\\t100\\t80\", \"O8;H10\", \"stx2-a\", \"Positive\", \"-\"),\n",
    "    (\"sample3\", \"1__fliC__H7__X\\t100\\t100\\t70\", \"-;H7\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample4\", \"bad_line\\n2__wzy__O111__X\\t100\\t100\\t70\\n3__fliC__H11__X\\t100\\t100\\t70\", \"-;H11\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample5\", \"\", \"-;-\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample6\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O157__X\\t100\\t100\\t65\\n3__wzt__O8__X\\t100\\t100\\t60\\n4__wzm__O8__X\\t100\\t100\\t65\\n5__fli__H2__X\\t100\\t100\\t70\", \"-;H2\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample7\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O111__X\\t100\\t100\\t65\\n3__fliC__H9__X\\t100\\t100\\t70\", \"-;H9\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample8\", \"1__fli__H1__X\\t100\\t100\\t70\\n2__fliC__H12__X\\t100\\t100\\t70\", \"-;H1\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample9\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O157__X\\t100\\t100\\t65\\n3__wzt__O8__X\\t100\\t100\\t60\\n4__wzm__O8__X\\t100\\t100\\t65\\n5__fliC__H10__X\\t100\\t100\\t70\\n6__fli__H2__X\\t100\\t100\\t70\\n7__stx1__stx1-a__X\\t100\\t100\\t90\\n8__stx2__stx2-d__X\\t100\\t100\\t90\\n9__stx2__stx2-a__X\\t100\\t100\\t90\\n10__eae__eae-42-5__X\\t100\\t100\\t80\\n11__ehxA__ehxA-7__X\\t100\\t100\\t80\", \"-;H2\", \"stx1-a;stx2-a;stx2-d\", \"Positive\", \"Positive\"),\n",
    "    (\"sample10\", \"1__adk__adk__X\\t100\\t100\\t70\\n2__fliC__H4__X\\t100\\t100\\t70\", \"-;H4\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample11\", \"1__eae__eae-1__X\\t100\\t94\\t70\\n2__fliC__H6__X\\t100\\t100\\t70\", \"-;H6\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample12\", \"1__stx1__stx1a__X\\t100\\t100\\t80\\n2__stx2__stx2c__X\\t100\\t100\\t85\\n3__fli__H21__X\\t100\\t100\\t70\", \"-;H21\", \"stx1a;stx2c\", \"-\", \"-\"),\n",
    "]\n",
    "\n",
    "for sample_name, res_content, expected_oh, expected_stx, expected_eae, expected_ehxA in test_cases:\n",
    "    with TemporaryDirectory() as tmpdir:\n",
    "        tmpdir = Path(tmpdir)\n",
    "        os.chdir(tmpdir)\n",
    "\n",
    "        res_dir = tmpdir / f\"examples/Results/{sample_name}/kma\"\n",
    "        res_dir.mkdir(parents=True)\n",
    "        res_file = res_dir / f\"{sample_name}.res\"\n",
    "        res_file.write_text(\"#Template\\tTemplate_Coverage\\tQuery_Identity\\tDepth\\n\" + res_content)\n",
    "\n",
    "        sheet = tmpdir / \"samplesheet.tsv\"\n",
    "        sheet.write_text(\n",
    "            \"sample_name\\tIllumina_read_files\\tNanopore_read_file\\tassembly_file\\torganism\\tvariant\\tnotes\\n\"\n",
    "            f\"{sample_name}\\tread1.fastq,read2.fastq\\t-\\t-\\tEcoli\\t-\\t-\\n\"\n",
    "        )\n",
    "\n",
    "        results = EcoliResults.from_samplesheet(sheet)\n",
    "        df = results.results_df\n",
    "        row = df.iloc[0]\n",
    "        \n",
    "        # general output and functionality test\n",
    "        assert row[\"sample_name\"] == sample_name\n",
    "        \n",
    "        if row[\"OH\"] != expected_oh:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected OH: {expected_oh}\\nActual OH: {row['OH']}\")\n",
    "        assert row[\"OH\"] == expected_oh\n",
    "        \n",
    "        if row[\"stx\"] != expected_stx:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected stx: {expected_stx}\\nActual stx: {row['stx']}\")\n",
    "        assert row[\"stx\"] == expected_stx\n",
    "\n",
    "        if row[\"eae\"] != expected_eae:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected eae: {expected_eae}\\nActual eae: {row['eae']}\")\n",
    "        assert row[\"eae\"] == expected_eae\n",
    "\n",
    "        if row[\"ehxA\"] != expected_ehxA:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected ehxA: {expected_ehxA}\\nActual ehxA: {row['ehxA']}\")\n",
    "        assert row[\"ehxA\"] == expected_ehxA\n",
    "\n",
    "        # sample specific information tests\n",
    "        \n",
    "        # without confliciting O and H typing, the OH column should be filled and the remaining four genes empty\n",
    "        if sample_name == \"sample1\": \n",
    "            assert row[\"wzx\"] == \"-\"\n",
    "            assert row[\"wzy\"] == \"-\"\n",
    "            assert row[\"wzt\"] == \"-\"\n",
    "            assert row[\"wzm\"] == \"-\"\n",
    "        # with conflicts the OH should remain empty and the four 'conflicting' gene information remain filled\n",
    "        elif sample_name == \"sample6\":\n",
    "            assert row[\"wzx\"] == \"O157\"\n",
    "            assert row[\"wzy\"] == \"O157\"\n",
    "            assert row[\"wzt\"] == \"O8\"\n",
    "            assert row[\"wzm\"] == \"O8\"\n",
    "        elif sample_name == \"sample10\":\n",
    "            assert row[\"Other\"] == \"adk\"\n",
    "\n",
    "print(\"All 12 syntehtic E. coli sample inline tests passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directive for ensuring that the code in your notebook get executed as a script\n",
    "\n",
    "The code-block here below is required to ensure that the code in the notebook is also transferred to the module (script), otherwise it will just be a notebook. See [Coding in NBdev](https://dksund.sharepoint.com/:fl:/g/contentstorage/CSP_7c761ee7-b577-4e08-8517-bc82392bf65e/ETlSfUyArSNJhX8veMI_JQ8By1aXGHzDJkhotpfpXx4mmw?e=037EwH&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF83Yzc2MWVlNy1iNTc3LTRlMDgtODUxNy1iYzgyMzkyYmY2NWUmZD1iJTIxNXg1MmZIZTFDRTZGRjd5Q09TdjJYblkwVlNiWXFYcE1yaHVrVmZqTVJUVEE4X1VwZjhTd1JxcjRNdmFrSmh2RCZmPTAxVlVLVzVWSlpLSjZVWkFGTkVORVlLN1pQUERCRDZKSVAmYz0lMkYmYT1Mb29wQXBwJnA9JTQwZmx1aWR4JTJGbG9vcC1wYWdlLWNvbnRhaW5lciZ4PSU3QiUyMnclMjIlM0ElMjJUMFJUVUh4a2EzTjFibVF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUUxZURVeVpraGxNVU5GTmtaR04zbERUMU4yTWxodVdUQldVMkpaY1Zod1RYSm9kV3RXWm1wTlVsUlVRVGhmVlhCbU9GTjNVbkZ5TkUxMllXdEthSFpFZkRBeFZsVkxWelZXU1RJMVJsaFBNalkyUlZkQ1FqTTFRVmhKVTBkRFVVcFdXa1klM0QlMjIlMkMlMjJpJTIyJTNBJTIyNzRmNzM1ZmUtYzg4Ny00MjhhLWFkZmYtNTEyZTg2YmNmZmQzJTIyJTdE) \n",
    "(**Writing your own notebooks**) on loop for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nbdev'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# | hide\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This is included at the end to ensure when you run through your notebook the code is also transferred to the module and isn't just a notebook\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnbdev\u001b[39;00m\n\u001b[32m      5\u001b[39m nbdev.nbdev_export()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nbdev'"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# This is included at the end to ensure when you run through your notebook the code is also transferred to the module and isn't just a notebook\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FBI_RAAH_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
