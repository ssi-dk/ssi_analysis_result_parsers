{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directive for creating a script for your notebook\n",
    "\n",
    "The block here below is required at the top of each notebook that you want to create a script for. You will also need to edit the \"settings.ini\" file, to create a script (see [Coding in NBdev](https://dksund.sharepoint.com/:fl:/g/contentstorage/CSP_7c761ee7-b577-4e08-8517-bc82392bf65e/ETlSfUyArSNJhX8veMI_JQ8By1aXGHzDJkhotpfpXx4mmw?e=037EwH&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF83Yzc2MWVlNy1iNTc3LTRlMDgtODUxNy1iYzgyMzkyYmY2NWUmZD1iJTIxNXg1MmZIZTFDRTZGRjd5Q09TdjJYblkwVlNiWXFYcE1yaHVrVmZqTVJUVEE4X1VwZjhTd1JxcjRNdmFrSmh2RCZmPTAxVlVLVzVWSlpLSjZVWkFGTkVORVlLN1pQUERCRDZKSVAmYz0lMkYmYT1Mb29wQXBwJnA9JTQwZmx1aWR4JTJGbG9vcC1wYWdlLWNvbnRhaW5lciZ4PSU3QiUyMnclMjIlM0ElMjJUMFJUVUh4a2EzTjFibVF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUUxZURVeVpraGxNVU5GTmtaR04zbERUMU4yTWxodVdUQldVMkpaY1Zod1RYSm9kV3RXWm1wTlVsUlVRVGhmVlhCbU9GTjNVbkZ5TkUxMllXdEthSFpFZkRBeFZsVkxWelZXU1RJMVJsaFBNalkyUlZkQ1FqTTFRVmhKVTBkRFVVcFdXa1klM0QlMjIlMkMlMjJpJTIyJTNBJTIyNzRmNzM1ZmUtYzg4Ny00MjhhLWFkZmYtNTEyZTg2YmNmZmQzJTIyJTdE) \n",
    "(**Writing your own notebooks**) on loop for more details). Replace **some_string** with a name that makes sense for your notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Ecoli_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "Include all the libraries which should be used in this module. You can also import modules from other notebooks; here, we have imported the functions in the core notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "from fastcore.script import call_parse\n",
    "#import functions from core module (optional, but most likely needed). \n",
    "from ssi_analysis_result_parsers import(\n",
    "    core\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\n",
    "os.chdir(core.PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "Add your code here below. If your notebook will be used as a console-script, you need to add a \"cli\"-function, at the end (see [Coding in NBdev](https://dksund.sharepoint.com/:fl:/g/contentstorage/CSP_7c761ee7-b577-4e08-8517-bc82392bf65e/ETlSfUyArSNJhX8veMI_JQ8By1aXGHzDJkhotpfpXx4mmw?e=037EwH&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF83Yzc2MWVlNy1iNTc3LTRlMDgtODUxNy1iYzgyMzkyYmY2NWUmZD1iJTIxNXg1MmZIZTFDRTZGRjd5Q09TdjJYblkwVlNiWXFYcE1yaHVrVmZqTVJUVEE4X1VwZjhTd1JxcjRNdmFrSmh2RCZmPTAxVlVLVzVWSlpLSjZVWkFGTkVORVlLN1pQUERCRDZKSVAmYz0lMkYmYT1Mb29wQXBwJnA9JTQwZmx1aWR4JTJGbG9vcC1wYWdlLWNvbnRhaW5lciZ4PSU3QiUyMnclMjIlM0ElMjJUMFJUVUh4a2EzTjFibVF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUUxZURVeVpraGxNVU5GTmtaR04zbERUMU4yTWxodVdUQldVMkpaY1Zod1RYSm9kV3RXWm1wTlVsUlVRVGhmVlhCbU9GTjNVbkZ5TkUxMllXdEthSFpFZkRBeFZsVkxWelZXU1RJMVJsaFBNalkyUlZkQ1FqTTFRVmhKVTBkRFVVcFdXa1klM0QlMjIlMkMlMjJpJTIyJTNBJTIyNzRmNzM1ZmUtYzg4Ny00MjhhLWFkZmYtNTEyZTg2YmNmZmQzJTIyJTdE) \n",
    "(**Code execution** and **Input, output and options**) on loop for more details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds & Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "thresholds = {\n",
    "    \"stx\": [98, 98],\n",
    "    \"wzx\": [98, 98],\n",
    "    \"wzy\": [98, 98],\n",
    "    \"wzt\": [98, 98],\n",
    "    \"wzm\": [98, 98],\n",
    "    \"fliC\": [90, 90],\n",
    "    \"fli\": [90, 90],\n",
    "    \"eae\": [95, 95],\n",
    "    \"ehxA\": [95, 95],\n",
    "    \"other\": [98, 98]\n",
    "}\n",
    "\n",
    "def setup_logging(log_dir: str, sample_name: str) -> None:\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file = os.path.join(log_dir, f\"{sample_name}_kma_fbi.log\")\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    while logger.hasHandlers():\n",
    "        logger.removeHandler(logger.handlers[0])\n",
    "\n",
    "    logging.basicConfig(\n",
    "        filename=log_file,\n",
    "        filemode=\"a\",\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        level=logging.INFO\n",
    "    )\n",
    "\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    logging.info(f\"Logging started for {log_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds filtering & .res parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_threshold(template_name: str, thresholds: Dict[str, List[int]]) -> List[int]:\n",
    "    for key in thresholds:\n",
    "        if key in template_name:\n",
    "            return thresholds[key]\n",
    "    return thresholds[\"other\"]\n",
    "\n",
    "def process_res_file(res_file_path: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        res_df = pd.read_csv(res_file_path, sep=\"\\t\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File not found: {res_file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(f\"File is empty or not properly formatted: {res_file_path}\")\n",
    "\n",
    "    required_columns = {\"#Template\", \"Template_Coverage\", \"Query_Identity\", \"Depth\"}\n",
    "    if not required_columns.issubset(res_df.columns):\n",
    "        raise ValueError(f\"Missing expected columns in {res_file_path}\")\n",
    "\n",
    "    res_df[\"threshold\"] = res_df[\"#Template\"].apply(lambda x: get_threshold(x, thresholds))\n",
    "    res_df_filtered = res_df[\n",
    "        (res_df[\"Template_Coverage\"] >= res_df[\"threshold\"].apply(lambda x: x[0])) &\n",
    "        (res_df[\"Query_Identity\"] >= res_df[\"threshold\"].apply(lambda x: x[1]))\n",
    "    ]\n",
    "    return res_df_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escherichia coli results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class EcoliResults:\n",
    "    \"\"\"\n",
    "    Object for holding and processing E. coli typing results.\n",
    "    \"\"\"\n",
    "\n",
    "    # converts the sample results in dict to pandas df\n",
    "    def __init__(self, results_dict: dict):\n",
    "        self.results_dict = results_dict\n",
    "        self.results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\").reset_index(names=\"sample_name\")\n",
    "\n",
    "    @staticmethod\n",
    "    def summarize_single_sample(sample_name: str, res_path: str, verbose_flag: int = 1) -> dict:\n",
    "        log_dir = \"examples/Log\"\n",
    "        setup_logging(log_dir, sample_name)\n",
    "\n",
    "        NA_string = \"-\"\n",
    "        output_data = {\n",
    "            \"stx\": NA_string,\n",
    "            \"OH\": NA_string, \"wzx\": NA_string, \"wzy\": NA_string, \"wzt\": NA_string, \"wzm\": NA_string,\n",
    "            \"eae\": NA_string, \"ehxA\": NA_string,\n",
    "            \"Other\": NA_string\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            logging.info(f\"Processing .res file: {res_path}\")\n",
    "            filtered_df = process_res_file(res_path)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to process {res_path}: {e}\")\n",
    "            return output_data\n",
    "\n",
    "        gene_map = {\n",
    "            \"wzx\": \"wzx\", \"wzy\": \"wzy\", \"wzt\": \"wzt\", \"wzm\": \"wzm\",\n",
    "            \"eae\": \"eae\", \"ehxA\": \"ehxA\"\n",
    "        }\n",
    "        toxin = \"stx\"\n",
    "        stx_alleles = set()\n",
    "        fli = NA_string\n",
    "        fliC = NA_string\n",
    "\n",
    "        for template in filtered_df[\"#Template\"]:\n",
    "            parts = template.split(\"__\")\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            gene, allele = parts[1], parts[2]\n",
    "\n",
    "            if gene in [\"eae\", \"ehxA\"]:\n",
    "                output_data[gene] = \"Positive\"\n",
    "            elif gene in gene_map:\n",
    "                output_data[gene] = allele\n",
    "            elif gene == \"fliC\":\n",
    "                fliC = allele\n",
    "            elif gene == \"fli\":\n",
    "                fli = allele\n",
    "            elif gene.startswith(toxin):\n",
    "                stx_alleles.add(allele)\n",
    "            elif gene not in thresholds:\n",
    "                output_data[\"Other\"] = allele\n",
    "\n",
    "        if stx_alleles:\n",
    "            output_data[toxin] = \";\".join(sorted(stx_alleles))\n",
    "\n",
    "        wzx, wzy, wzt, wzm = output_data[\"wzx\"], output_data[\"wzy\"], output_data[\"wzt\"], output_data[\"wzm\"]\n",
    "        Otype = \"-\"\n",
    "        if wzx != NA_string and wzy != NA_string and wzx == wzy and wzt == NA_string and wzm == NA_string:\n",
    "            Otype = wzx\n",
    "            output_data[\"wzx\"] = output_data[\"wzy\"] = NA_string\n",
    "        elif wzt != NA_string and wzm != NA_string and wzt == wzm and wzx == NA_string and wzy == NA_string:\n",
    "            Otype = wzt\n",
    "            output_data[\"wzt\"] = output_data[\"wzm\"] = NA_string\n",
    "\n",
    "        Htype = fli if fli != NA_string else fliC\n",
    "        output_data[\"OH\"] = f\"{Otype};{Htype}\"\n",
    "\n",
    "        if verbose_flag == 1:\n",
    "            verbose_parts = []\n",
    "            for _, row in filtered_df.iterrows():\n",
    "                parts = row[\"#Template\"].split(\"__\")\n",
    "                if len(parts) >= 3:\n",
    "                    gene, allele = parts[1], parts[2]\n",
    "                    depth = row[\"Depth\"]\n",
    "                    coverage = row[\"Template_Coverage\"]\n",
    "                    identity = row[\"Query_Identity\"]\n",
    "                    verbose_parts.append(f\"{gene}_{allele}_{depth:.2f}_{coverage:.2f}_{identity:.2f}\")\n",
    "            output_data[\"verbose\"] = \";\".join(verbose_parts)\n",
    "\n",
    "        logging.info(f\"Successfully processed sample: {sample_name}\")\n",
    "        return output_data\n",
    "\n",
    "    @classmethod\n",
    "    def from_samplesheet(cls, samplesheet_path: Path, verbose: int = 1) -> \"EcoliResults\":\n",
    "        df = pd.read_csv(samplesheet_path, sep=\"\\t\")\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        if \"Illumina_read_files\" in df.columns and (\"read1\" not in df.columns or \"read2\" not in df.columns):\n",
    "            df[[\"read1\", \"read2\"]] = df[\"Illumina_read_files\"].str.split(\",\", expand=True)\n",
    "\n",
    "        results_dict = {}\n",
    "        for idx, row in df.iterrows():\n",
    "            sample_name = row[\"sample_name\"]\n",
    "            res_path = f\"examples/Results/{sample_name}/kma/{sample_name}.res\"\n",
    "            summary = cls.summarize_single_sample(sample_name, res_path, verbose_flag=verbose)\n",
    "            results_dict[sample_name] = summary\n",
    "        return cls(results_dict)\n",
    "\n",
    "    def write_tsv(self, output_file: Path):\n",
    "        self.results_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<EcoliResults: {len(self.results_df)} samples, {len(self.results_df.columns)} variables>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@call_parse\n",
    "def ecoli_parser(\n",
    "    samplesheet_path: Path,  # Input samplesheet\n",
    "    output_file: Path = None,  # Path to output\n",
    "    verbose: int = 1,  # Verbosity\n",
    "):\n",
    "    results = EcoliResults.from_samplesheet(samplesheet_path, verbose=verbose)\n",
    "    if output_file:\n",
    "        results.write_tsv(output_file)\n",
    "    else:\n",
    "        print(results.results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "\n",
    "test_cases = [\n",
    "    # sample_name, res_content, expected_oh, expected_stx, expected_eae, expected_ehxA\n",
    "    (\"sample1\", \"1__wzx__O103__X\\t100\\t100\\t60\\n2__wzy__O103__X\\t100\\t100\\t65\\n3__fliC__H2__X\\t100\\t100\\t70\", \"O103;H2\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample2\", \"1__wzt__O8__X\\t100\\t100\\t60\\n2__wzm__O8__X\\t100\\t100\\t65\\n3__fliC__H10__X\\t100\\t100\\t70\\n4__stx2__stx2-a__X\\t100\\t100\\t90\\n5__eae__eae-5__X\\t100\\t100\\t80\", \"O8;H10\", \"stx2-a\", \"Positive\", \"-\"),\n",
    "    (\"sample3\", \"1__fliC__H7__X\\t100\\t100\\t70\", \"-;H7\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample4\", \"bad_line\\n2__wzy__O111__X\\t100\\t100\\t70\\n3__fliC__H11__X\\t100\\t100\\t70\", \"-;H11\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample5\", \"\", \"-;-\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample6\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O157__X\\t100\\t100\\t65\\n3__wzt__O8__X\\t100\\t100\\t60\\n4__wzm__O8__X\\t100\\t100\\t65\\n5__fli__H2__X\\t100\\t100\\t70\", \"-;H2\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample7\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O111__X\\t100\\t100\\t65\\n3__fliC__H9__X\\t100\\t100\\t70\", \"-;H9\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample8\", \"1__fli__H1__X\\t100\\t100\\t70\\n2__fliC__H12__X\\t100\\t100\\t70\", \"-;H1\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample9\", \"1__wzx__O157__X\\t100\\t100\\t60\\n2__wzy__O157__X\\t100\\t100\\t65\\n3__wzt__O8__X\\t100\\t100\\t60\\n4__wzm__O8__X\\t100\\t100\\t65\\n5__fliC__H10__X\\t100\\t100\\t70\\n6__fli__H2__X\\t100\\t100\\t70\\n7__stx1__stx1-a__X\\t100\\t100\\t90\\n8__stx2__stx2-d__X\\t100\\t100\\t90\\n9__stx2__stx2-a__X\\t100\\t100\\t90\\n10__eae__eae-42-5__X\\t100\\t100\\t80\\n11__ehxA__ehxA-7__X\\t100\\t100\\t80\", \"-;H2\", \"stx1-a;stx2-a;stx2-d\", \"Positive\", \"Positive\"),\n",
    "    (\"sample10\", \"1__adk__adk__X\\t100\\t100\\t70\\n2__fliC__H4__X\\t100\\t100\\t70\", \"-;H4\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample11\", \"1__eae__eae-1__X\\t100\\t94\\t70\\n2__fliC__H6__X\\t100\\t100\\t70\", \"-;H6\", \"-\", \"-\", \"-\"),\n",
    "    (\"sample12\", \"1__stx1__stx1a__X\\t100\\t100\\t80\\n2__stx2__stx2c__X\\t100\\t100\\t85\\n3__fli__H21__X\\t100\\t100\\t70\", \"-;H21\", \"stx1a;stx2c\", \"-\", \"-\"),\n",
    "]\n",
    "\n",
    "for sample_name, res_content, expected_oh, expected_stx, expected_eae, expected_ehxA in test_cases:\n",
    "    with TemporaryDirectory() as tmpdir:\n",
    "        tmpdir = Path(tmpdir)\n",
    "        os.chdir(tmpdir)\n",
    "\n",
    "        res_dir = tmpdir / f\"examples/Results/{sample_name}/kma\"\n",
    "        res_dir.mkdir(parents=True)\n",
    "        res_file = res_dir / f\"{sample_name}.res\"\n",
    "        res_file.write_text(\"#Template\\tTemplate_Coverage\\tQuery_Identity\\tDepth\\n\" + res_content)\n",
    "\n",
    "        sheet = tmpdir / \"samplesheet.tsv\"\n",
    "        sheet.write_text(\n",
    "            \"sample_name\\tIllumina_read_files\\tNanopore_read_file\\tassembly_file\\torganism\\tvariant\\tnotes\\n\"\n",
    "            f\"{sample_name}\\tread1.fastq,read2.fastq\\t-\\t-\\tEcoli\\t-\\t-\\n\"\n",
    "        )\n",
    "\n",
    "        results = EcoliResults.from_samplesheet(sheet)\n",
    "        df = results.results_df\n",
    "        row = df.iloc[0]\n",
    "        \n",
    "        # general output and functionality test\n",
    "        assert row[\"sample_name\"] == sample_name\n",
    "        \n",
    "        if row[\"OH\"] != expected_oh:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected OH: {expected_oh}\\nActual OH: {row['OH']}\")\n",
    "        assert row[\"OH\"] == expected_oh\n",
    "        \n",
    "        if row[\"stx\"] != expected_stx:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected stx: {expected_stx}\\nActual stx: {row['stx']}\")\n",
    "        assert row[\"stx\"] == expected_stx\n",
    "\n",
    "        if row[\"eae\"] != expected_eae:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected eae: {expected_eae}\\nActual eae: {row['eae']}\")\n",
    "        assert row[\"eae\"] == expected_eae\n",
    "\n",
    "        if row[\"ehxA\"] != expected_ehxA:\n",
    "            raise AssertionError(f\"\\nSample: {sample_name}\\nExpected ehxA: {expected_ehxA}\\nActual ehxA: {row['ehxA']}\")\n",
    "        assert row[\"ehxA\"] == expected_ehxA\n",
    "\n",
    "        # sample specific information tests\n",
    "        \n",
    "        # without confliciting O and H typing, the OH column should be filled and the remaining four genes empty\n",
    "        if sample_name == \"sample1\": \n",
    "            assert row[\"wzx\"] == \"-\"\n",
    "            assert row[\"wzy\"] == \"-\"\n",
    "            assert row[\"wzt\"] == \"-\"\n",
    "            assert row[\"wzm\"] == \"-\"\n",
    "        # with conflicts the OH should remain empty and the four 'conflicting' gene information remain filled\n",
    "        elif sample_name == \"sample6\":\n",
    "            assert row[\"wzx\"] == \"O157\"\n",
    "            assert row[\"wzy\"] == \"O157\"\n",
    "            assert row[\"wzt\"] == \"O8\"\n",
    "            assert row[\"wzm\"] == \"O8\"\n",
    "        elif sample_name == \"sample10\":\n",
    "            assert row[\"Other\"] == \"adk\"\n",
    "\n",
    "print(\"All 12 E. coli inline tests passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directive for ensuring that the code in your notebook get executed as a script\n",
    "\n",
    "The code-block here below is required to ensure that the code in the notebook is also transferred to the module (script), otherwise it will just be a notebook. See [Coding in NBdev](https://dksund.sharepoint.com/:fl:/g/contentstorage/CSP_7c761ee7-b577-4e08-8517-bc82392bf65e/ETlSfUyArSNJhX8veMI_JQ8By1aXGHzDJkhotpfpXx4mmw?e=037EwH&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF83Yzc2MWVlNy1iNTc3LTRlMDgtODUxNy1iYzgyMzkyYmY2NWUmZD1iJTIxNXg1MmZIZTFDRTZGRjd5Q09TdjJYblkwVlNiWXFYcE1yaHVrVmZqTVJUVEE4X1VwZjhTd1JxcjRNdmFrSmh2RCZmPTAxVlVLVzVWSlpLSjZVWkFGTkVORVlLN1pQUERCRDZKSVAmYz0lMkYmYT1Mb29wQXBwJnA9JTQwZmx1aWR4JTJGbG9vcC1wYWdlLWNvbnRhaW5lciZ4PSU3QiUyMnclMjIlM0ElMjJUMFJUVUh4a2EzTjFibVF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUUxZURVeVpraGxNVU5GTmtaR04zbERUMU4yTWxodVdUQldVMkpaY1Zod1RYSm9kV3RXWm1wTlVsUlVRVGhmVlhCbU9GTjNVbkZ5TkUxMllXdEthSFpFZkRBeFZsVkxWelZXU1RJMVJsaFBNalkyUlZkQ1FqTTFRVmhKVTBkRFVVcFdXa1klM0QlMjIlMkMlMjJpJTIyJTNBJTIyNzRmNzM1ZmUtYzg4Ny00MjhhLWFkZmYtNTEyZTg2YmNmZmQzJTIyJTdE) \n",
    "(**Writing your own notebooks**) on loop for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# This is included at the end to ensure when you run through your notebook the code is also transferred to the module and isn't just a notebook\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
