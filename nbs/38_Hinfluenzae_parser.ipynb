{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directive for creating a script for your notebook\n",
    "\n",
    "The block here below is required at the top of each notebook that you want to create a script for. You will also need to edit the \"settings.ini\" file, to create a script (see [Coding in NBdev](https://dksund.sharepoint.com/:fl:/g/contentstorage/CSP_7c761ee7-b577-4e08-8517-bc82392bf65e/ETlSfUyArSNJhX8veMI_JQ8By1aXGHzDJkhotpfpXx4mmw?e=037EwH&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF83Yzc2MWVlNy1iNTc3LTRlMDgtODUxNy1iYzgyMzkyYmY2NWUmZD1iJTIxNXg1MmZIZTFDRTZGRjd5Q09TdjJYblkwVlNiWXFYcE1yaHVrVmZqTVJUVEE4X1VwZjhTd1JxcjRNdmFrSmh2RCZmPTAxVlVLVzVWSlpLSjZVWkFGTkVORVlLN1pQUERCRDZKSVAmYz0lMkYmYT1Mb29wQXBwJnA9JTQwZmx1aWR4JTJGbG9vcC1wYWdlLWNvbnRhaW5lciZ4PSU3QiUyMnclMjIlM0ElMjJUMFJUVUh4a2EzTjFibVF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUUxZURVeVpraGxNVU5GTmtaR04zbERUMU4yTWxodVdUQldVMkpaY1Zod1RYSm9kV3RXWm1wTlVsUlVRVGhmVlhCbU9GTjNVbkZ5TkUxMllXdEthSFpFZkRBeFZsVkxWelZXU1RJMVJsaFBNalkyUlZkQ1FqTTFRVmhKVTBkRFVVcFdXa1klM0QlMjIlMkMlMjJpJTIyJTNBJTIyNzRmNzM1ZmUtYzg4Ny00MjhhLWFkZmYtNTEyZTg2YmNmZmQzJTIyJTdE) \n",
    "(**Writing your own notebooks**) on loop for more details). Replace **some_string** with a name that makes sense for your notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp Hinfluenzae_parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "Include all the libraries which should be used in this module. You can also import modules from other notebooks; here, we have imported the functions in the core notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "# standard libs\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Common to template\n",
    "# add into settings.ini, requirements, package name is python-dotenv, for conda build ensure `conda config --add channels conda-forge`\n",
    "import dotenv  # for loading config from .env files, https://pypi.org/project/python-dotenv/\n",
    "import envyaml  # Allows to loads env vars into a yaml file, https://github.com/thesimj/envyaml\n",
    "import fastcore  # To add functionality related to nbdev development, https://github.com/fastai/fastcore/\n",
    "from fastcore import (\n",
    "    test,\n",
    ")\n",
    "from fastcore.script import (\n",
    "    call_parse,\n",
    ")  # for @call_parse, https://fastcore.fast.ai/script\n",
    "import json  # for nicely printing json and yaml\n",
    "\n",
    "#import functions from core module (optional, but most likely needed). \n",
    "from ssi_analysis_result_parsers import(\n",
    "    core,\n",
    "    blast_parser,\n",
    ")\n",
    "#from ssi_analysis_result_parsers.blast_parser import extract_presence_absence\n",
    "\n",
    "# Project specific libraries\n",
    "from pathlib import Path\n",
    "import pandas\n",
    "import numpy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block should never be exported. It is to have python running in the project (and not the nbs) dir, and to initiate the package using pip.\n",
    "os.chdir(core.PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "Add your code here below. If your notebook will be used as a console-script, you need to add a \"cli\"-function, at the end (see [Coding in NBdev](https://dksund.sharepoint.com/:fl:/g/contentstorage/CSP_7c761ee7-b577-4e08-8517-bc82392bf65e/ETlSfUyArSNJhX8veMI_JQ8By1aXGHzDJkhotpfpXx4mmw?e=037EwH&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF83Yzc2MWVlNy1iNTc3LTRlMDgtODUxNy1iYzgyMzkyYmY2NWUmZD1iJTIxNXg1MmZIZTFDRTZGRjd5Q09TdjJYblkwVlNiWXFYcE1yaHVrVmZqTVJUVEE4X1VwZjhTd1JxcjRNdmFrSmh2RCZmPTAxVlVLVzVWSlpLSjZVWkFGTkVORVlLN1pQUERCRDZKSVAmYz0lMkYmYT1Mb29wQXBwJnA9JTQwZmx1aWR4JTJGbG9vcC1wYWdlLWNvbnRhaW5lciZ4PSU3QiUyMnclMjIlM0ElMjJUMFJUVUh4a2EzTjFibVF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUUxZURVeVpraGxNVU5GTmtaR04zbERUMU4yTWxodVdUQldVMkpaY1Zod1RYSm9kV3RXWm1wTlVsUlVRVGhmVlhCbU9GTjNVbkZ5TkUxMllXdEthSFpFZkRBeFZsVkxWelZXU1RJMVJsaFBNalkyUlZkQ1FqTTFRVmhKVTBkRFVVcFdXa1klM0QlMjIlMkMlMjJpJTIyJTNBJTIyNzRmNzM1ZmUtYzg4Ny00MjhhLWFkZmYtNTEyZTg2YmNmZmQzJTIyJTdE) \n",
    "(**Code execution** and **Input, output and options**) on loop for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def get_biotype_from_gene_presence(biotype_gene_presence_dict: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Convert biotype gene presence dict to biotype\n",
    "    \"\"\"\n",
    "\n",
    "    if biotype_gene_presence_dict[\"indole\"] == \"1\":\n",
    "        if biotype_gene_presence_dict[\"urease\"] == \"1\":\n",
    "            if biotype_gene_presence_dict[\"ODC\"] == \"1\":\n",
    "                biotype = \"I\"\n",
    "            else:\n",
    "                biotype = \"II\"\n",
    "        else:\n",
    "            if biotype_gene_presence_dict[\"ODC\"] == \"1\":\n",
    "                biotype = \"V\"\n",
    "            else:\n",
    "                biotype = \"VII\"\n",
    "    else:\n",
    "        if biotype_gene_presence_dict[\"urease\"] == \"1\":\n",
    "            if biotype_gene_presence_dict[\"ODC\"] == \"1\":\n",
    "                biotype = \"IV\"\n",
    "            else:\n",
    "                biotype = \"III\"\n",
    "        else:\n",
    "            if biotype_gene_presence_dict[\"ODC\"] == \"1\":\n",
    "                biotype = \"VI\"\n",
    "            else:\n",
    "                biotype = \"VIII\"\n",
    "    return {\"biotype\": biotype}\n",
    "\n",
    "\n",
    "def extract_hicap_results(hicap_tsv: Path):\n",
    "    if hicap_tsv.exists():\n",
    "        try:\n",
    "            df = pandas.read_csv(hicap_tsv, sep='\\t')\n",
    "            if df.shape[0]>0:\n",
    "                serotype = df.iloc[0][\"predicted_serotype\"]\n",
    "                serotype_attributes = df.iloc[0][\"attributes\"]\n",
    "                serotype_genes = df.iloc[0][\"genes_identified\"]\n",
    "            else:\n",
    "                print(f\"Hicap output file empty at {hicap_tsv}\", file=sys.stderr)\n",
    "                return None\n",
    "        except pandas.errors.EmptyDataError:\n",
    "            print(f\"Hicap output file empty at {hicap_tsv}\", file=sys.stderr)\n",
    "            return None\n",
    "    else:\n",
    "        serotype = \"-\"\n",
    "        serotype_attributes = \"no_capsule_genes_found\"\n",
    "        serotype_genes = \"-\"\n",
    "\n",
    "    return {\"serotype\": serotype, \"serotype_attributes\": serotype_attributes, \"serotype_genes\": serotype_genes}\n",
    "\n",
    "\n",
    "def extract_ariba_ftsI_snps(ariba_output_tsv: Path, ftsI_types_tsv: Path):\n",
    "    if not ftsI_types_tsv.exists():\n",
    "        print(f\"Failed to load ftsI types table at {ftsI_types_tsv}\")\n",
    "        return None\n",
    "    elif ariba_output_tsv.exists():\n",
    "        ftsI_types = {}\n",
    "        ftsI_table_snps = []\n",
    "        with open(ftsI_types_tsv) as f:\n",
    "            for line in f:\n",
    "                line = line.rstrip('\\n').split('\\t')\n",
    "                print(line)\n",
    "                if line[0] == 'pos':\n",
    "                    positions = line[1:]\n",
    "                elif line[0] == 'Ref':\n",
    "                    refs = line[1:]\n",
    "                elif line[0] == 'Diverse':\n",
    "                    snps = line[1:]\n",
    "                    for n in range(len(snps)):\n",
    "                        snp_split = snps[n].split('/')\n",
    "                        for snp in snp_split:\n",
    "                            ftsI_table_snps.append(refs[n]+positions[n]+snp)\n",
    "                else:\n",
    "                    type = line[0]\n",
    "                    vars = line[1:]\n",
    "                    type_vars = []\n",
    "                    for n in range(len(vars)):\n",
    "                        var = vars[n]\n",
    "                        if var != '' and var != ' ':\n",
    "                            type_vars.append(refs[n]+positions[n]+var)\n",
    "                    ftsI_types[type] = type_vars\n",
    "\n",
    "        change_list = []\n",
    "        ftsI_gene_snps = []\n",
    "        with open(ariba_output_tsv) as f:\n",
    "            for line in f:\n",
    "                line = line.rstrip('\\n').split('\\t')\n",
    "                if line[0] != '#ariba_ref_name':\n",
    "                    change = line[18]\n",
    "                    ftsI_gene_snps.append(change)\n",
    "                    if change in ftsI_table_snps:\n",
    "                        change_list.append(change)\n",
    "\n",
    "        match_var_counts = {}\n",
    "        for type in ftsI_types:\n",
    "            var_list = ftsI_types[type]\n",
    "            match_var_count = 0\n",
    "            for var in var_list:\n",
    "                if var in change_list:\n",
    "                    match_var_count += 1\n",
    "            match_var_counts[type] = [match_var_count,len(var_list)]\n",
    "        best_match = 0\n",
    "        best_type = '-'\n",
    "        for type in match_var_counts:\n",
    "            check_list = match_var_counts[type]\n",
    "            if check_list[0] == check_list[1] and check_list[0] > best_match:\n",
    "                best_match = check_list[0]\n",
    "                best_type = type\n",
    "    else:\n",
    "        print(f\"No ariba report found at {ariba_output_tsv}\")\n",
    "        return None\n",
    "    return {\"ftsI_type\": best_type, \"key_ftsI_snps\": change_list, \"all_ftsI_snps\": ftsI_gene_snps}\n",
    "\n",
    "\n",
    "\n",
    "class HinfluenzaeResults(core.PipelineResults):\n",
    "\n",
    "    @classmethod\n",
    "    def from_tool_paths(cls, legionella_sbt_results_tsv: Path, lag1_blast_tsv: Path, sample_name = None):\n",
    "        \"\"\"\n",
    "        Alternative constructor for initializing results for single sample,\n",
    "        Initializes HinfluenzaeResults instance provided paths to outputs from tools (legionella sbt and lag1 presence blast)\n",
    "        \"\"\"\n",
    "        hinfluenze_results = cls.summary(legionella_sbt_results_tsv=legionella_sbt_results_tsv,\n",
    "                                         lag1_blast_tsv=lag1_blast_tsv)\n",
    "        return cls( {sample_name: hinfluenze_results})\n",
    "    \n",
    "    @classmethod\n",
    "    def from_tool_paths_dict(cls, file_paths: dict):\n",
    "        \"\"\"\n",
    "        Alternative constructor for initializing results for multiple samples,\n",
    "        Initializes HinfluenzaeResults instance by providing a dictionary of paths to outputs from tools (legionella sbt and lag1 presence blast)\n",
    "        \"\"\"\n",
    "        results_dict = {}\n",
    "        for sample_name, path_dict in file_paths.items():\n",
    "            hinfluenze_results = cls.summary(legionella_sbt_results_tsv=Path(path_dict[\"sbt_results\"]),\n",
    "                                             lag1_blast_tsv=Path(path_dict[\"lag1_blast_results\"]))\n",
    "            results_dict[sample_name] = hinfluenze_results\n",
    "        return cls(results_dict)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_tool_paths_dataframe(cls, file_paths_df: pandas.DataFrame):\n",
    "        \"\"\"\n",
    "        Alternative constructor for initializing results for multiple samples,\n",
    "        Initializes HinfluenzaeResults instance by providing a DataFrame of paths to outputs from tools (legionella sbt and lag1 presence blast)\n",
    "        \"\"\"\n",
    "        file_paths_df.replace(numpy.nan, None, inplace=True)\n",
    "        file_paths = file_paths_df.to_dict(orient=\"index\")\n",
    "        results_dict = {}\n",
    "        for sample_name, path_dict in file_paths.items():\n",
    "            hinfluenze_results = cls.summary(legionella_sbt_results_tsv=Path(path_dict[\"sbt_results\"]),\n",
    "                                             lag1_blast_tsv=Path(path_dict[\"lag1_blast_results\"]))\n",
    "            print(hinfluenze_results)\n",
    "            results_dict[sample_name] = hinfluenze_results\n",
    "        return cls(results_dict)\n",
    "\n",
    "    @classmethod\n",
    "    def from_tool_paths_tsv(cls, tool_paths_tsv: Path):\n",
    "        \"\"\"\n",
    "        Alternative constructor for initializing results for multiple samples,\n",
    "        Initializes HinfluenzaeResults instance by providing a tsv-file with paths to outputs from tools (legionella sbt and lag1 presence blast)\n",
    "        \"\"\"\n",
    "        file_paths_df = pandas.read_csv(tool_paths_tsv, sep='\\t')\n",
    "        file_paths_df.set_index(\"sample_name\", inplace=True, drop=True)\n",
    "        return cls.from_tool_paths_dataframe(file_paths_df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def summary(ftsI_ariba_tsv: Path, biotype_blast_tsv: Path, ) -> dict:\n",
    "        biotype_gene_dict = blast_parser.extract_presence_absence(blast_output_tsv = biotype_blast_tsv,\n",
    "                                                                    hits_as_string = False,\n",
    "                                                                    include_match_stats = False,\n",
    "                                                                    gene_names = [\"indole\",\"urease\",\"ODC\"])\n",
    "        biotype_dict = get_biotype_from_gene_presence(biotype_gene_presence_dict=biotype_gene_dict)\n",
    "        results_dict = core.update_results_dict(biotype_gene_dict, biotype_dict, old_duplicate_key_prefix=\"_\")\n",
    "        if results_dict is None:\n",
    "            return {}\n",
    "        return results_dict\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return(f\"< Hinfluenzae analysis results object. {len(self.results_df)} samples with {len(self.results_df.columns)} result variables > \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indole': '0', 'urease': '0', 'ODC': '1'}\n",
      "{'biotype': 'VI'}\n",
      "{'serotype': 'type_e', 'serotype_attributes': 'full_gene_complement,fragmented_locus', 'serotype_genes': 'bexA,bexB,bexC,bexD,ecs1,ecs2,ecs3;ecs4,ecs5,ecs6,ecs7,ecs8,hcsA,hcsB'}\n",
      "['pos', '311', '337', '350', '352', '357', '368', '377', '385', '389', '437', '443', '449', '490', '501', '502', '511', '517', '526', '528', '530', '532', '547', '562', '569', '586']\n",
      "['Ref', 'S', 'A', 'D', 'S', 'S', 'A', 'M', 'S', 'L', 'A', 'T', 'I', 'G', 'R', 'A', 'V', 'R', 'N', 'Y', 'A', 'T', 'V', 'V', 'N', 'A']\n",
      "['I', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'H', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['IIa', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['IIb', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'V', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['IIc', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'T', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['IId', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'V', ' ', ' ', ' ', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['III', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'T', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['III+', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'T', 'F', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['III like', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'T', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'H', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['III like +', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'T', 'F', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'H', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['Diverse', 'P', 'V/N', 'N', 'T/N/F', 'N', 'T', 'I', 'T', 'F', 'S', 'A', 'V', 'E', 'E/L/H', 'T/V', 'A', 'H', 'K', 'H', 'S', 'S', 'I', 'L', 'S', 'S']\n",
      "{'ftsI_type': '-', 'key_ftsI_snps': [], 'all_ftsI_snps': ['A22T', 'A239E', 'I475L', 'E603D']}\n",
      "['pos', '311', '337', '350', '352', '357', '368', '377', '385', '389', '437', '443', '449', '490', '501', '502', '511', '517', '526', '528', '530', '532', '547', '562', '569', '586']\n",
      "['Ref', 'S', 'A', 'D', 'S', 'S', 'A', 'M', 'S', 'L', 'A', 'T', 'I', 'G', 'R', 'A', 'V', 'R', 'N', 'Y', 'A', 'T', 'V', 'V', 'N', 'A']\n",
      "['I', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'H', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['IIa', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['IIb', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'V', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['IIc', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'T', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['IId', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'V', ' ', ' ', ' ', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['III', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'T', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['III+', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'T', 'F', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'K', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['III like', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'T', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'H', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['III like +', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'T', 'F', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'H', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['Diverse', 'P', 'V/N', 'N', 'T/N/F', 'N', 'T', 'I', 'T', 'F', 'S', 'A', 'V', 'E', 'E/L/H', 'T/V', 'A', 'H', 'K', 'H', 'S', 'S', 'I', 'L', 'S', 'S']\n",
      "{'ftsI_type': '-', 'key_ftsI_snps': ['V547I'], 'all_ftsI_snps': ['P31S', 'K310E', 'V547I']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nf = HinfluenzaeResults.from_results_tsv(\"./test_output/test_batch_output.tsv\")\\nassert(len(f) == 2)\\nassert(f.results_dict[\"sample_1\"][\"ST\"] == 23)\\n\\n\\nf = HinfluenzaeResults.from_tool_paths_dict(file_paths=  {\"sample_1\": {\"sbt_results\": \"test_input/Legionella/test.sbt.tsv\", \"lag1_blast_results\": \"test_input/Legionella/lag-1_blast.tsv\"},\\n                                                            \"sample_2\": {\"sbt_results\": \"test_input/Legionella/test2.sbt.tsv\", \"lag1_blast_results\": \"test_input/Legionella/lag-1_blast_2.tsv\"}})\\n\\n\\n\\nf = HinfluenzaeResults.from_tool_paths(legionella_sbt_results_tsv=\"test_input/Legionella/test.sbt.tsv\",\\n                                      lag1_blast_tsv=\"test_input/Legionella/lag-1_blast.tsv\")\\n\\n\\n\\nf = HinfluenzaeResults.from_tool_paths_tsv(tool_paths_tsv=\"test_input/Legionella/batch_parser_file_paths.tsv\")\\n\\nassert(len(f) == 4)\\nassert(len(f.results_df) == 4)\\nassert(len(f.results_df.columns) == 10)\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "biotype_blast_tsv = \"test_input/Hinfluenzae/biotype/sample1.biotype.blast.tsv\"\n",
    "\n",
    "biotype_gene_dict = blast_parser.extract_presence_absence(blast_output_tsv = biotype_blast_tsv,\n",
    "                                                                    hits_as_string = False,\n",
    "                                                                    include_match_stats = False,\n",
    "                                                                    gene_names = [\"indole\",\"urease\",\"ODC\"])\n",
    "biotype_dict = get_biotype_from_gene_presence(biotype_gene_presence_dict=biotype_gene_dict)\n",
    "\n",
    "print(biotype_gene_dict)\n",
    "print(biotype_dict)\n",
    "\n",
    "hicap_results = extract_hicap_results(Path(\"test_input/Hinfluenzae/hicap/sample1.hicap.tsv\"))\n",
    "print(hicap_results)\n",
    "\n",
    "\n",
    "ftsI_results = extract_ariba_ftsI_snps(ariba_output_tsv=Path(\"test_input/Hinfluenzae/ariba_ftsI/sample1.ftsI.ariba.tsv\"),ftsI_types_tsv=Path(\"test_input/Hinfluenzae/ariba_ftsI/ftsI_types_table.txt\"))\n",
    "print(ftsI_results)\n",
    "\n",
    "ftsI_results = extract_ariba_ftsI_snps(ariba_output_tsv=Path(\"test_input/Hinfluenzae/ariba_ftsI/sample2.ftsI.ariba.tsv\"),ftsI_types_tsv=Path(\"test_input/Hinfluenzae/ariba_ftsI/ftsI_types_table.txt\"))\n",
    "print(ftsI_results)\n",
    "\"\"\"\n",
    "f = HinfluenzaeResults.from_results_tsv(\"./test_output/test_batch_output.tsv\")\n",
    "assert(len(f) == 2)\n",
    "assert(f.results_dict[\"sample_1\"][\"ST\"] == 23)\n",
    "\n",
    "\n",
    "f = HinfluenzaeResults.from_tool_paths_dict(file_paths=  {\"sample_1\": {\"sbt_results\": \"test_input/Legionella/test.sbt.tsv\", \"lag1_blast_results\": \"test_input/Legionella/lag-1_blast.tsv\"},\n",
    "                                                            \"sample_2\": {\"sbt_results\": \"test_input/Legionella/test2.sbt.tsv\", \"lag1_blast_results\": \"test_input/Legionella/lag-1_blast_2.tsv\"}})\n",
    "\n",
    "\n",
    "\n",
    "f = HinfluenzaeResults.from_tool_paths(legionella_sbt_results_tsv=\"test_input/Legionella/test.sbt.tsv\",\n",
    "                                      lag1_blast_tsv=\"test_input/Legionella/lag-1_blast.tsv\")\n",
    "\n",
    "\n",
    "\n",
    "f = HinfluenzaeResults.from_tool_paths_tsv(tool_paths_tsv=\"test_input/Legionella/batch_parser_file_paths.tsv\")\n",
    "\n",
    "assert(len(f) == 4)\n",
    "assert(len(f.results_df) == 4)\n",
    "assert(len(f.results_df.columns) == 10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def legionella_parser(\n",
    "    legionella_sbt_file: Path = None,  # Path \"*.sbt.tsv from legionella_sbt program\"\n",
    "    lag_1_blast_output: Path = None, #  Path to output from lag1_blast. Generated with blastn -query lag-1.fasta -subject assembly.fasta -outfmt \"6 qseqid sseqid pident length qlen qstart qend sstart send sseq evalue bitscore\"\n",
    "    output_file: Path = None,  # Path to output tsv\n",
    "    sample_name: str = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    hinfluenze_results = HinfluenzaeResults.from_tool_paths(legionella_sbt_results_tsv=legionella_sbt_file,\n",
    "                                                           lag1_blast_tsv=lag_1_blast_output,\n",
    "                                                           sample_name=sample_name)\n",
    "    hinfluenze_results.write_tsv(output_file=output_file)\n",
    "\n",
    "@call_parse\n",
    "def legionella_batch_parser(\n",
    "    file_path_tsv: Path = None,  # Path to tsv containing file paths to the outputs from tools to be parsed. Must contain headers \"sample_name\", \"sbt_results\", and \"lag1_blast_results\"\n",
    "    output_file: Path = None,  # Path to output tsv\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    hinfluenze_results = HinfluenzaeResults.from_tool_paths_tsv(tool_paths_tsv=file_path_tsv)\n",
    "    hinfluenze_results.write_tsv(output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directive for ensuring that the code in your notebook get executed as a script\n",
    "\n",
    "The code-block here below is required to ensure that the code in the notebook is also transferred to the module (script), otherwise it will just be a notebook. See [Coding in NBdev](https://dksund.sharepoint.com/:fl:/g/contentstorage/CSP_7c761ee7-b577-4e08-8517-bc82392bf65e/ETlSfUyArSNJhX8veMI_JQ8By1aXGHzDJkhotpfpXx4mmw?e=037EwH&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF83Yzc2MWVlNy1iNTc3LTRlMDgtODUxNy1iYzgyMzkyYmY2NWUmZD1iJTIxNXg1MmZIZTFDRTZGRjd5Q09TdjJYblkwVlNiWXFYcE1yaHVrVmZqTVJUVEE4X1VwZjhTd1JxcjRNdmFrSmh2RCZmPTAxVlVLVzVWSlpLSjZVWkFGTkVORVlLN1pQUERCRDZKSVAmYz0lMkYmYT1Mb29wQXBwJnA9JTQwZmx1aWR4JTJGbG9vcC1wYWdlLWNvbnRhaW5lciZ4PSU3QiUyMnclMjIlM0ElMjJUMFJUVUh4a2EzTjFibVF1YzJoaGNtVndiMmx1ZEM1amIyMThZaUUxZURVeVpraGxNVU5GTmtaR04zbERUMU4yTWxodVdUQldVMkpaY1Zod1RYSm9kV3RXWm1wTlVsUlVRVGhmVlhCbU9GTjNVbkZ5TkUxMllXdEthSFpFZkRBeFZsVkxWelZXU1RJMVJsaFBNalkyUlZkQ1FqTTFRVmhKVTBkRFVVcFdXa1klM0QlMjIlMkMlMjJpJTIyJTNBJTIyNzRmNzM1ZmUtYzg4Ny00MjhhLWFkZmYtNTEyZTg2YmNmZmQzJTIyJTdE) \n",
    "(**Writing your own notebooks**) on loop for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# This is included at the end to ensure when you run through your notebook the code is also transferred to the module and isn't just a notebook\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
